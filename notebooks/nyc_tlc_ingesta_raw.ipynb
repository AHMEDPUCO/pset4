{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c8002b3",
   "metadata": {},
   "source": [
    "# Notebook 01: Ingesta Parquet → Postgres RAW\n",
    "## NYC TLC Taxi Trips 2015-2025 (Yellow & Green)\n",
    "\n",
    "**Objetivo**: Backfill completo de datos NYC TLC desde archivos Parquet públicos hacia PostgreSQL en el esquema `raw`.\n",
    "\n",
    "**Alcance**:\n",
    "- Yellow Taxi: 2015-2025\n",
    "- Green Taxi: 2015-2025\n",
    "- Taxi Zone Lookup (catálogo de zonas)\n",
    "\n",
    "**Proceso**:\n",
    "1. Configuración y conexión a Postgres\n",
    "2. Descarga de archivos Parquet desde NYC TLC\n",
    "3. Estandarización de columnas\n",
    "4. **Limpieza de datos** (validaciones de negocio)\n",
    "5. Inserción en `raw.yellow_taxi_trip` y `raw.green_taxi_trip`\n",
    "6. Carga de `raw.taxi_zone_lookup`\n",
    "7. Validación y reportes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a251e6",
   "metadata": {},
   "source": [
    "## 1. Configuración inicial y variables de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f617037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración cargada:\n",
      "  - Postgres: admin@postgres:5432/nyc_taxi\n",
      "  - Schema RAW: raw\n",
      "  - Años: 2015-2025\n",
      "  - Servicios: ['yellow']\n",
      "  - RUN_ID: localtest\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "from urllib.request import urlretrieve\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, current_timestamp, when, unix_timestamp, abs as spark_abs\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType, TimestampType\n",
    "\n",
    "# Cargar variables de ambiente\n",
    "PG_HOST = os.getenv('PG_HOST', 'postgres')\n",
    "PG_PORT = os.getenv('PG_PORT', '5432')\n",
    "PG_DB = os.getenv('PG_DB', 'nyc_tlc')\n",
    "PG_USER = os.getenv('PG_USER', 'postgres')\n",
    "PG_PASSWORD = os.getenv('PG_PASSWORD', 'postgres')\n",
    "PG_SCHEMA_RAW = os.getenv('PG_SCHEMA_RAW', 'raw')\n",
    "\n",
    "# Parámetros de ingesta\n",
    "YEARS = list(range(2015, 2026))  # 2015-2025\n",
    "MONTHS = list(range(1, 13))      # 1-12\n",
    "SERVICES = ['yellow']   # Tipos de taxi\n",
    "RUN_ID = os.getenv('RUN_ID', f\"ingesta_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\")\n",
    "\n",
    "# URL base para los archivos Parquet de NYC TLC\n",
    "BASE_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data\"\n",
    "\n",
    "print(\"Configuración cargada:\")\n",
    "print(f\"  - Postgres: {PG_USER}@{PG_HOST}:{PG_PORT}/{PG_DB}\")\n",
    "print(f\"  - Schema RAW: {PG_SCHEMA_RAW}\")\n",
    "print(f\"  - Años: {YEARS[0]}-{YEARS[-1]}\")\n",
    "print(f\"  - Servicios: {SERVICES}\")\n",
    "print(f\"  - RUN_ID: {RUN_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0089a24c",
   "metadata": {},
   "source": [
    "## 2. Inicialización de Spark Session con conexión a Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a753e767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark 3.5.0 inicializado correctamente\n",
      "Master: local[*]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crear SparkSession con driver JDBC para Postgres\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"NYC_TLC_Ingesta_Raw\")\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.6.0\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# Nivel de logs\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(f\"Spark {spark.version} inicializado correctamente\")\n",
    "print(f\"Master: {spark.sparkContext.master}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e1507",
   "metadata": {},
   "source": [
    "## 3. Funciones de utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac27e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones de utilidad cargadas correctamente\n"
     ]
    }
   ],
   "source": [
    "def build_url(service: str, year: int, month: int) -> str:\n",
    "    \"\"\"Construye la URL del archivo Parquet para un servicio, año y mes específicos.\"\"\"\n",
    "    filename = f\"{service}_tripdata_{year}-{month:02d}.parquet\"\n",
    "    return f\"{BASE_URL}/{filename}\"\n",
    "\n",
    "def download_to_temp(url: str) -> str:\n",
    "    \"\"\"Descarga un archivo Parquet a un directorio temporal y retorna la ruta.\"\"\"\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    filename = url.split('/')[-1]\n",
    "    local_path = os.path.join(temp_dir, filename)\n",
    "    if not os.path.exists(local_path):\n",
    "        print(f\"  Descargando: {filename}...\", end=\" \")\n",
    "        urlretrieve(url, local_path)\n",
    "        print(\"OK\")\n",
    "    else:\n",
    "        print(f\"  Usando caché local: {filename}\")\n",
    "    return local_path\n",
    "\n",
    "def get_postgres_jdbc_url() -> str:\n",
    "    \"\"\"Construye la URL JDBC para Postgres.\"\"\"\n",
    "    return f\"jdbc:postgresql://{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    "\n",
    "def get_postgres_properties() -> dict:\n",
    "    \"\"\"Retorna las propiedades de conexión JDBC.\"\"\"\n",
    "    return {\n",
    "        \"user\": PG_USER,\n",
    "        \"password\": PG_PASSWORD,\n",
    "        \"driver\": \"org.postgresql.Driver\"\n",
    "    }\n",
    "\n",
    "print(\"Funciones de utilidad cargadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1739e9",
   "metadata": {},
   "source": [
    "## 4. Estandarización de columnas por servicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96f8349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función de estandarización cargada\n"
     ]
    }
   ],
   "source": [
    "def standardize_columns(df, service: str):\n",
    "    \"\"\"\n",
    "    Estandariza nombres de columnas y tipos de datos según el servicio.\n",
    "\n",
    "    Yellow: tpep_pickup_datetime, tpep_dropoff_datetime\n",
    "    Green: lpep_pickup_datetime, lpep_dropoff_datetime, trip_type\n",
    "    \"\"\"\n",
    "    # Mapeo de columnas comunes (minúsculas y snake_case)\n",
    "    column_mapping = {\n",
    "        'VendorID': 'VendorID',\n",
    "        'RatecodeID': 'RatecodeID',\n",
    "        'PULocationID': 'PULocationID',\n",
    "        'DOLocationID': 'DOLocationID',\n",
    "        'passenger_count': 'passenger_count',\n",
    "        'trip_distance': 'trip_distance',\n",
    "        'fare_amount': 'fare_amount',\n",
    "        'extra': 'extra',\n",
    "        'mta_tax': 'mta_tax',\n",
    "        'tip_amount': 'tip_amount',\n",
    "        'tolls_amount': 'tolls_amount',\n",
    "        'improvement_surcharge': 'improvement_surcharge',\n",
    "        'total_amount': 'total_amount',\n",
    "        'payment_type': 'payment_type',\n",
    "        'congestion_surcharge': 'congestion_surcharge',\n",
    "        'airport_fee': 'airport_fee',\n",
    "        'store_and_fwd_flag': 'store_and_fwd_flag'\n",
    "    }\n",
    "    # Renombrar columnas que existan en el DataFrame\n",
    "    for old_name, new_name in column_mapping.items():\n",
    "        if old_name in df.columns and old_name != new_name:\n",
    "            df = df.withColumnRenamed(old_name, new_name)\n",
    "    # Timestamps específicos por servicio\n",
    "    if service == 'yellow':\n",
    "        if 'tpep_pickup_datetime' in df.columns:\n",
    "            df = df.withColumn('tpep_pickup_datetime', col('tpep_pickup_datetime').cast(TimestampType()))\n",
    "        if 'tpep_dropoff_datetime' in df.columns:\n",
    "            df = df.withColumn('tpep_dropoff_datetime', col('tpep_dropoff_datetime').cast(TimestampType()))\n",
    "    elif service == 'green':\n",
    "        if 'lpep_pickup_datetime' in df.columns:\n",
    "            df = df.withColumn('lpep_pickup_datetime', col('lpep_pickup_datetime').cast(TimestampType()))\n",
    "        if 'lpep_dropoff_datetime' in df.columns:\n",
    "            df = df.withColumn('lpep_dropoff_datetime', col('lpep_dropoff_datetime').cast(TimestampType()))\n",
    "        if 'trip_type' in df.columns:\n",
    "            df = df.withColumn('trip_type', col('trip_type').cast(IntegerType()))\n",
    "    # Castear tipos de datos comunes\n",
    "    numeric_int_cols = ['VendorID', 'RatecodeID', 'PULocationID', 'DOLocationID', 'passenger_count', 'payment_type']\n",
    "    numeric_double_cols = ['trip_distance', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
    "                           'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'airport_fee']\n",
    "    for col_name in numeric_int_cols:\n",
    "        if col_name in df.columns:\n",
    "            df = df.withColumn(col_name, col(col_name).cast(IntegerType()))\n",
    "    for col_name in numeric_double_cols:\n",
    "        if col_name in df.columns:\n",
    "            df = df.withColumn(col_name, col(col_name).cast(DoubleType()))\n",
    "    if 'store_and_fwd_flag' in df.columns:\n",
    "        df = df.withColumn('store_and_fwd_flag', col('store_and_fwd_flag').cast(StringType()))\n",
    "    return df\n",
    "\n",
    "print(\"Función de estandarización cargada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46396902",
   "metadata": {},
   "source": [
    "## 5. Limpieza y validación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c3e5afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función de limpieza cargada\n"
     ]
    }
   ],
   "source": [
    "def clean_taxi_data(df, service: str):\n",
    "    \"\"\"\n",
    "    Limpieza robusta de datos NYC TLC Yellow/Green taxi trips.\n",
    "\n",
    "    Reglas de validación:\n",
    "    1. Timestamps válidos y lógicos (pickup < dropoff)\n",
    "    2. LocationID válidos (1-263 según NYC TLC)\n",
    "    3. Passenger count razonable (1-6, casos extremos hasta 9)\n",
    "    4. Trip distance positiva y realista (< 500 millas)\n",
    "    5. Montos no negativos y realistas\n",
    "    6. Rate codes válidos (1-6)\n",
    "    7. Payment types válidos (1-6)\n",
    "    8. Vendor IDs válidos (1-2, algunos 4)\n",
    "    9. Duración de viaje razonable (> 1 min, < 24 hrs)\n",
    "    10. Consistencia en montos\n",
    "    \"\"\"\n",
    "    initial_count = df.count()\n",
    "    print(f\"    [CLEAN] Filas iniciales: {initial_count:,}\")\n",
    "    pickup_col = 'tpep_pickup_datetime' if service == 'yellow' else 'lpep_pickup_datetime'\n",
    "    dropoff_col = 'tpep_dropoff_datetime' if service == 'yellow' else 'lpep_dropoff_datetime'\n",
    "    df = df.filter((col(pickup_col).isNotNull()) & (col(dropoff_col).isNotNull()))\n",
    "    df = df.filter(col(pickup_col) < col(dropoff_col))\n",
    "    df = df.filter((col(pickup_col) >= lit('2015-01-01')) & (col(pickup_col) <= lit('2025-12-31')))\n",
    "    trip_duration_seconds = unix_timestamp(col(dropoff_col)) - unix_timestamp(col(pickup_col))\n",
    "    df = df.filter((trip_duration_seconds >= 60) & (trip_duration_seconds <= 86400))\n",
    "    df = df.filter((col('PULocationID').between(1, 263)) & (col('DOLocationID').between(1, 263)))\n",
    "    df = df.withColumn('passenger_count',\n",
    "        when(col('passenger_count').isNull(), 1)\n",
    "        .when(col('passenger_count') < 1, 1)\n",
    "        .when(col('passenger_count') > 9, 9)\n",
    "        .otherwise(col('passenger_count'))\n",
    "    )\n",
    "    df = df.filter((col('trip_distance') > 0) & (col('trip_distance') < 500))\n",
    "    df = df.filter(col('fare_amount') > 0)\n",
    "    df = df.filter((col('total_amount') > 0) & (col('total_amount') < 1000))\n",
    "    money_columns = ['extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge', 'airport_fee']\n",
    "    for col_name in money_columns:\n",
    "        if col_name in df.columns:\n",
    "            df = df.withColumn(col_name, when(col(col_name).isNull(), 0).when(col(col_name) < 0, 0).otherwise(col(col_name)))\n",
    "    df = df.withColumn('RatecodeID', when(col('RatecodeID').isNull(), 1).when(~col('RatecodeID').between(1, 6), 1).otherwise(col('RatecodeID')))\n",
    "    df = df.filter(col('payment_type').between(1, 6))\n",
    "    df = df.filter(col('VendorID').isin([1, 2, 4]))\n",
    "    if service == 'green' and 'trip_type' in df.columns:\n",
    "        df = df.withColumn('trip_type', when(col('trip_type').isNull(), 1).when(~col('trip_type').isin([1, 2]), 1).otherwise(col('trip_type')))\n",
    "    required_cols = ['fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge']\n",
    "    if all(c in df.columns for c in required_cols):\n",
    "        expected_total = (col('fare_amount') + col('extra') + col('mta_tax') + col('tip_amount') + col('tolls_amount') + col('improvement_surcharge'))\n",
    "        if 'congestion_surcharge' in df.columns:\n",
    "            expected_total = expected_total + col('congestion_surcharge')\n",
    "        if 'airport_fee' in df.columns:\n",
    "            expected_total = expected_total + col('airport_fee')\n",
    "        df = df.filter(spark_abs(col('total_amount') - expected_total) <= 5)\n",
    "    if 'store_and_fwd_flag' in df.columns:\n",
    "        df = df.withColumn('store_and_fwd_flag',\n",
    "            when(col('store_and_fwd_flag').isNull(), 'N')\n",
    "            .when(col('store_and_fwd_flag').isin(['Y', 'y', '1', 'true', 'True']), 'Y')\n",
    "            .otherwise('N')\n",
    "        )\n",
    "    final_count = df.count()\n",
    "    removed = initial_count - final_count\n",
    "    pct_removed = (removed / initial_count * 100) if initial_count > 0 else 0\n",
    "    print(f\"    [CLEAN] Filas válidas: {final_count:,} ({removed:,} removidas, {pct_removed:.2f}%)\")\n",
    "    return df\n",
    "\n",
    "print(\"Función de limpieza cargada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ea231d",
   "metadata": {},
   "source": [
    "## 6. Agregar metadatos de ingesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f768343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función de metadatos cargada\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, current_timestamp\n",
    "\n",
    "def add_metadata(df, year: int, month: int, run_id: str):\n",
    "    \"\"\"Agrega columnas de metadatos para trazabilidad de la ingesta.\"\"\"\n",
    "    return (\n",
    "        df\n",
    "        .withColumn('run_id', lit(run_id))\n",
    "        .withColumn('source_year', lit(year))\n",
    "        .withColumn('source_month', lit(month))\n",
    "        .withColumn('ingested_at_utc', current_timestamp())\n",
    "    )\n",
    "\n",
    "print(\"Función de metadatos cargada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5df224d",
   "metadata": {},
   "source": [
    "## 7. Escritura a Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27e036e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función de escritura a Postgres cargada\n"
     ]
    }
   ],
   "source": [
    "def write_batch(df, table_name: str, mode: str = \"overwrite\", writers: int = 4, batchsize: int = 5000):\n",
    "    # número de writers\n",
    "    df_to_write = df.coalesce(writers) \n",
    "\n",
    "    (df_to_write.write\n",
    "        .format(\"jdbc\")\n",
    "        .option(\"url\", get_postgres_jdbc_url())\n",
    "        .option(\"dbtable\", table_name)\n",
    "        .option(\"user\", PG_USER)\n",
    "        .option(\"password\", PG_PASSWORD)\n",
    "        .option(\"driver\", \"org.postgresql.Driver\")\n",
    "        .option(\"batchsize\", str(batchsize))   # tamaño de lote JDBC\n",
    "        # .option(\"isolationLevel\", \"READ_COMMITTED\")  # opcional\n",
    "        .mode(mode)\n",
    "        .save()\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Función de escritura a Postgres cargada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87009fe",
   "metadata": {},
   "source": [
    "## 8. Creación de esquemas y tablas en Postgres\n",
    "\n",
    "Antes de la ingesta, creamos los esquemas `raw` y `analytics` si no existen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c511bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esquemas 'raw' y 'analytics' verificados/creados\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "def create_schemas():\n",
    "    \"\"\"Crea los esquemas raw y analytics si no existen.\"\"\"\n",
    "    conn = psycopg2.connect(\n",
    "        host=PG_HOST,\n",
    "        port=PG_PORT,\n",
    "        database=PG_DB,\n",
    "        user=PG_USER,\n",
    "        password=PG_PASSWORD\n",
    "    )\n",
    "    conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"CREATE SCHEMA IF NOT EXISTS {PG_SCHEMA_RAW};\")\n",
    "    cursor.execute(\"CREATE SCHEMA IF NOT EXISTS analytics;\")\n",
    "    print(f\"Esquemas '{PG_SCHEMA_RAW}' y 'analytics' verificados/creados\")\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "# Ejecutar creación de esquemas\n",
    "create_schemas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ade259c",
   "metadata": {},
   "source": [
    "## 9. INGESTA PRINCIPAL: Yellow & Green Taxi Trips (2015-2025)\n",
    "\n",
    "**Proceso por mes**:\n",
    "1. Descargar Parquet\n",
    "2. Estandarizar columnas\n",
    "3. **Limpiar y validar datos**\n",
    "4. Agregar metadatos\n",
    "5. Insertar en Postgres (`raw.yellow_taxi_trip` o `raw.green_taxi_trip`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5db6bf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INICIANDO BACKFILL 2015-2025 CON LIMPIEZA DE DATOS Y VERIFICACIÓN DE EXISTENCIA\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "SERVICIO: YELLOW → raw.yellow_taxi_trip\n",
      "================================================================================\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o41.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2015-01] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2015-01.parquet\n",
      "    Filas descargadas: 12,741,035\n",
      "    [CLEAN] Filas iniciales: 12,741,035\n",
      "    [CLEAN] Filas válidas: 12,373,047 (367,988 removidas, 2.89%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 12,373,047 filas insertadas \n",
      "         (367,988 removidas, 2.89%) en 250.0s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o458.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2015-02] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2015-02.parquet\n",
      "    Filas descargadas: 12,442,394\n",
      "    [CLEAN] Filas iniciales: 12,442,394\n",
      "    [CLEAN] Filas válidas: 12,074,350 (368,044 removidas, 2.96%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 12,074,350 filas insertadas \n",
      "         (368,044 removidas, 2.96%) en 220.5s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o875.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2015-03] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2015-03.parquet\n",
      "    [ERROR] An error occurred while calling o877.parquet.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 28.0 failed 1 times, most recent failure: Lost task 0.0 in stage 28.0 (TID 178) (8bc7c8e87b09 executor driver): org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:383)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)\n",
      "\tat org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:79)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: [CANNOT_READ_FILE_FOOTER] Could not read footer for file: file:/tmp/yellow_tripdata_2015-03.parquet. Please ensure that the file is in either ORC or Parquet format. If not, please convert it to a valid format. If the file is in the valid format, please check if it is corrupt. If it is, you can choose to either ignore it or fix the corruption.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.cannotReadFooterForFileError(QueryExecutionErrors.scala:1056)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:456)\n",
      "\tat org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:380)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)\n",
      "\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)\n",
      "Caused by: java.lang.RuntimeException: file:/tmp/yellow_tripdata_2015-03.parquet is not a Parquet file. Expected magic number at tail, but found [-24, -126, -7, -87]\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:565)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:799)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)\n",
      "\t... 14 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1046)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1045)\n",
      "\tat org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.mergeSchemasInParallel(SchemaMergeUtils.scala:73)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.mergeSchemasInParallel(ParquetFileFormat.scala:497)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetUtils$.inferSchema(ParquetUtils.scala:132)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.inferSchema(ParquetFileFormat.scala:79)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)\n",
      "\tat scala.Option.orElse(Option.scala:447)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:563)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:383)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)\n",
      "\tat org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:79)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\t... 1 more\n",
      "Caused by: org.apache.spark.SparkException: [CANNOT_READ_FILE_FOOTER] Could not read footer for file: file:/tmp/yellow_tripdata_2015-03.parquet. Please ensure that the file is in either ORC or Parquet format. If not, please convert it to a valid format. If the file is in the valid format, please check if it is corrupt. If it is, you can choose to either ignore it or fix the corruption.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.cannotReadFooterForFileError(QueryExecutionErrors.scala:1056)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:456)\n",
      "\tat org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:380)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)\n",
      "\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)\n",
      "Caused by: java.lang.RuntimeException: file:/tmp/yellow_tripdata_2015-03.parquet is not a Parquet file. Expected magic number at tail, but found [-24, -126, -7, -87]\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:565)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:799)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)\n",
      "\t... 14 more\n",
      "\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o889.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2015-04] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2015-04.parquet\n",
      "    Filas descargadas: 13,063,758\n",
      "    [CLEAN] Filas iniciales: 13,063,758\n",
      "    [CLEAN] Filas válidas: 12,715,364 (348,394 removidas, 2.67%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 12,715,364 filas insertadas \n",
      "         (348,394 removidas, 2.67%) en 237.9s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o1306.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2015-05] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2015-05.parquet\n",
      "    [ERROR] An error occurred while calling o1308.parquet.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 43.0 failed 1 times, most recent failure: Lost task 0.0 in stage 43.0 (TID 268) (8bc7c8e87b09 executor driver): org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:383)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)\n",
      "\tat org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:79)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: [CANNOT_READ_FILE_FOOTER] Could not read footer for file: file:/tmp/yellow_tripdata_2015-05.parquet. Please ensure that the file is in either ORC or Parquet format. If not, please convert it to a valid format. If the file is in the valid format, please check if it is corrupt. If it is, you can choose to either ignore it or fix the corruption.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.cannotReadFooterForFileError(QueryExecutionErrors.scala:1056)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:456)\n",
      "\tat org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:380)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)\n",
      "\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)\n",
      "Caused by: java.lang.RuntimeException: file:/tmp/yellow_tripdata_2015-05.parquet is not a Parquet file. Expected magic number at tail, but found [-68, -82, 89, 7]\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:565)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:799)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)\n",
      "\t... 14 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1046)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1045)\n",
      "\tat org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.mergeSchemasInParallel(SchemaMergeUtils.scala:73)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.mergeSchemasInParallel(ParquetFileFormat.scala:497)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetUtils$.inferSchema(ParquetUtils.scala:132)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.inferSchema(ParquetFileFormat.scala:79)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)\n",
      "\tat scala.Option.orElse(Option.scala:447)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:563)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:383)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)\n",
      "\tat org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:79)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\t... 1 more\n",
      "Caused by: org.apache.spark.SparkException: [CANNOT_READ_FILE_FOOTER] Could not read footer for file: file:/tmp/yellow_tripdata_2015-05.parquet. Please ensure that the file is in either ORC or Parquet format. If not, please convert it to a valid format. If the file is in the valid format, please check if it is corrupt. If it is, you can choose to either ignore it or fix the corruption.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.cannotReadFooterForFileError(QueryExecutionErrors.scala:1056)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:456)\n",
      "\tat org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:380)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)\n",
      "\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)\n",
      "Caused by: java.lang.RuntimeException: file:/tmp/yellow_tripdata_2015-05.parquet is not a Parquet file. Expected magic number at tail, but found [-68, -82, 89, 7]\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:565)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:799)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)\n",
      "\t... 14 more\n",
      "\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o1320.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2015-06] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2015-06.parquet... OK\n",
      "    Filas descargadas: 12,324,936\n",
      "    [CLEAN] Filas iniciales: 12,324,936\n",
      "    [CLEAN] Filas válidas: 12,014,400 (310,536 removidas, 2.52%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 12,014,400 filas insertadas \n",
      "         (310,536 removidas, 2.52%) en 376.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o1737.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2015-07] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2015-07.parquet... OK\n",
      "    Filas descargadas: 11,559,666\n",
      "    [CLEAN] Filas iniciales: 11,559,666\n",
      "    [CLEAN] Filas válidas: 11,275,272 (284,394 removidas, 2.46%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 11,275,272 filas insertadas \n",
      "         (284,394 removidas, 2.46%) en 541.5s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o2154.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2015-08] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2015-08.parquet... OK\n",
      "    Filas descargadas: 11,123,123\n",
      "    [CLEAN] Filas iniciales: 11,123,123\n",
      "    [CLEAN] Filas válidas: 10,849,590 (273,533 removidas, 2.46%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 10,849,590 filas insertadas \n",
      "         (273,533 removidas, 2.46%) en 507.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o2571.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2015-09] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2015-09.parquet... OK\n",
      "    Filas descargadas: 11,218,122\n",
      "    [CLEAN] Filas iniciales: 11,218,122\n",
      "    [CLEAN] Filas válidas: 10,944,846 (273,276 removidas, 2.44%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 10,944,846 filas insertadas \n",
      "         (273,276 removidas, 2.44%) en 658.9s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o2988.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2015-10] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2015-10.parquet... OK\n",
      "    Filas descargadas: 12,307,333\n",
      "    [CLEAN] Filas iniciales: 12,307,333\n",
      "    [CLEAN] Filas válidas: 12,004,359 (302,974 removidas, 2.46%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 12,004,359 filas insertadas \n",
      "         (302,974 removidas, 2.46%) en 447.4s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o3405.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2015-11] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2015-11.parquet... OK\n",
      "    Filas descargadas: 11,305,240\n",
      "    [CLEAN] Filas iniciales: 11,305,240\n",
      "    [CLEAN] Filas válidas: 11,015,821 (289,419 removidas, 2.56%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 11,015,821 filas insertadas \n",
      "         (289,419 removidas, 2.56%) en 534.4s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o3822.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2015-12] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2015-12.parquet... OK\n",
      "    Filas descargadas: 11,452,996\n",
      "    [CLEAN] Filas iniciales: 11,452,996\n",
      "    [CLEAN] Filas válidas: 11,163,698 (289,298 removidas, 2.53%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 11,163,698 filas insertadas \n",
      "         (289,298 removidas, 2.53%) en 350.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o4239.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2016-01] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2016-01.parquet... OK\n",
      "    Filas descargadas: 10,905,067\n",
      "    [CLEAN] Filas iniciales: 10,905,067\n",
      "    [CLEAN] Filas válidas: 10,622,604 (282,463 removidas, 2.59%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 10,622,604 filas insertadas \n",
      "         (282,463 removidas, 2.59%) en 326.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o4656.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2016-02] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2016-02.parquet... OK\n",
      "    Filas descargadas: 11,375,412\n",
      "    [CLEAN] Filas iniciales: 11,375,412\n",
      "    [CLEAN] Filas válidas: 11,084,237 (291,175 removidas, 2.56%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 11,084,237 filas insertadas \n",
      "         (291,175 removidas, 2.56%) en 346.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o5073.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2016-03] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2016-03.parquet... OK\n",
      "    Filas descargadas: 12,203,824\n",
      "    [CLEAN] Filas iniciales: 12,203,824\n",
      "    [CLEAN] Filas válidas: 11,899,792 (304,032 removidas, 2.49%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 11,899,792 filas insertadas \n",
      "         (304,032 removidas, 2.49%) en 405.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o5490.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2016-04] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2016-04.parquet... OK\n",
      "    Filas descargadas: 11,927,996\n",
      "    [CLEAN] Filas iniciales: 11,927,996\n",
      "    [CLEAN] Filas válidas: 11,630,636 (297,360 removidas, 2.49%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 11,630,636 filas insertadas \n",
      "         (297,360 removidas, 2.49%) en 436.4s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o5907.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2016-05] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2016-05.parquet... OK\n",
      "    Filas descargadas: 11,832,049\n",
      "    [CLEAN] Filas iniciales: 11,832,049\n",
      "    [CLEAN] Filas válidas: 11,557,487 (274,562 removidas, 2.32%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 11,557,487 filas insertadas \n",
      "         (274,562 removidas, 2.32%) en 489.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o6324.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2016-06] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2016-06.parquet... OK\n",
      "    Filas descargadas: 11,131,645\n",
      "    [CLEAN] Filas iniciales: 11,131,645\n",
      "    [CLEAN] Filas válidas: 10,870,534 (261,111 removidas, 2.35%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 10,870,534 filas insertadas \n",
      "         (261,111 removidas, 2.35%) en 391.1s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o6741.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2016-07] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2016-07.parquet... OK\n",
      "    Filas descargadas: 10,294,080\n",
      "    [CLEAN] Filas iniciales: 10,294,080\n",
      "    [CLEAN] Filas válidas: 10,041,248 (252,832 removidas, 2.46%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 10,041,248 filas insertadas \n",
      "         (252,832 removidas, 2.46%) en 479.5s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o7158.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2016-08] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2016-08.parquet... OK\n",
      "    Filas descargadas: 9,942,263\n",
      "    [CLEAN] Filas iniciales: 9,942,263\n",
      "    [CLEAN] Filas válidas: 9,698,408 (243,855 removidas, 2.45%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 9,698,408 filas insertadas \n",
      "         (243,855 removidas, 2.45%) en 502.6s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o7575.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2016-09] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2016-09.parquet... OK\n",
      "    Filas descargadas: 10,116,018\n",
      "    [CLEAN] Filas iniciales: 10,116,018\n",
      "    [CLEAN] Filas válidas: 9,870,541 (245,477 removidas, 2.43%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 9,870,541 filas insertadas \n",
      "         (245,477 removidas, 2.43%) en 570.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o7992.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2016-10] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2016-10.parquet... OK\n",
      "    Filas descargadas: 10,854,626\n",
      "    [CLEAN] Filas iniciales: 10,854,626\n",
      "    [CLEAN] Filas válidas: 10,585,832 (268,794 removidas, 2.48%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 10,585,832 filas insertadas \n",
      "         (268,794 removidas, 2.48%) en 850.6s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o8409.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2016-11] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2016-11.parquet... OK\n",
      "    Filas descargadas: 10,102,128\n",
      "    [CLEAN] Filas iniciales: 10,102,128\n",
      "    [CLEAN] Filas válidas: 9,840,234 (261,894 removidas, 2.59%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 9,840,234 filas insertadas \n",
      "         (261,894 removidas, 2.59%) en 558.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o8826.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2016-12] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2016-12.parquet... OK\n",
      "    Filas descargadas: 10,446,697\n",
      "    [CLEAN] Filas iniciales: 10,446,697\n",
      "    [CLEAN] Filas válidas: 10,136,728 (309,969 removidas, 2.97%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 10,136,728 filas insertadas \n",
      "         (309,969 removidas, 2.97%) en 423.0s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o9243.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2017-01] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2017-01.parquet... OK\n",
      "    Filas descargadas: 9,710,820\n",
      "    [CLEAN] Filas iniciales: 9,710,820\n",
      "    [CLEAN] Filas válidas: 9,440,932 (269,888 removidas, 2.78%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 9,440,932 filas insertadas \n",
      "         (269,888 removidas, 2.78%) en 327.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o9660.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2017-02] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2017-02.parquet... OK\n",
      "    Filas descargadas: 9,169,775\n",
      "    [CLEAN] Filas iniciales: 9,169,775\n",
      "    [CLEAN] Filas válidas: 8,918,292 (251,483 removidas, 2.74%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 8,918,292 filas insertadas \n",
      "         (251,483 removidas, 2.74%) en 218.0s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o10077.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2017-03] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2017-03.parquet... OK\n",
      "    Filas descargadas: 10,295,441\n",
      "    [CLEAN] Filas iniciales: 10,295,441\n",
      "    [CLEAN] Filas válidas: 9,996,843 (298,598 removidas, 2.90%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 9,996,843 filas insertadas \n",
      "         (298,598 removidas, 2.90%) en 302.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o10494.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2017-04] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2017-04.parquet... OK\n",
      "    Filas descargadas: 10,047,135\n",
      "    [CLEAN] Filas iniciales: 10,047,135\n",
      "    [CLEAN] Filas válidas: 9,788,269 (258,866 removidas, 2.58%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 9,788,269 filas insertadas \n",
      "         (258,866 removidas, 2.58%) en 340.4s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o10911.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2017-05] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2017-05.parquet... OK\n",
      "    Filas descargadas: 10,102,127\n",
      "    [CLEAN] Filas iniciales: 10,102,127\n",
      "    [CLEAN] Filas válidas: 9,840,709 (261,418 removidas, 2.59%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 9,840,709 filas insertadas \n",
      "         (261,418 removidas, 2.59%) en 334.5s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o11328.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2017-06] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2017-06.parquet... OK\n",
      "    Filas descargadas: 9,656,993\n",
      "    [CLEAN] Filas iniciales: 9,656,993\n",
      "    [CLEAN] Filas válidas: 9,407,585 (249,408 removidas, 2.58%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 9,407,585 filas insertadas \n",
      "         (249,408 removidas, 2.58%) en 249.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o11745.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2017-07] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2017-07.parquet... OK\n",
      "    Filas descargadas: 8,588,486\n",
      "    [CLEAN] Filas iniciales: 8,588,486\n",
      "    [CLEAN] Filas válidas: 8,371,208 (217,278 removidas, 2.53%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 8,371,208 filas insertadas \n",
      "         (217,278 removidas, 2.53%) en 222.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o12162.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2017-08] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2017-08.parquet... OK\n",
      "    Filas descargadas: 8,422,153\n",
      "    [CLEAN] Filas iniciales: 8,422,153\n",
      "    [CLEAN] Filas válidas: 8,215,276 (206,877 removidas, 2.46%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 8,215,276 filas insertadas \n",
      "         (206,877 removidas, 2.46%) en 238.0s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o12579.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2017-09] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2017-09.parquet... OK\n",
      "    Filas descargadas: 8,945,421\n",
      "    [CLEAN] Filas iniciales: 8,945,421\n",
      "    [CLEAN] Filas válidas: 8,723,660 (221,761 removidas, 2.48%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 8,723,660 filas insertadas \n",
      "         (221,761 removidas, 2.48%) en 225.4s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o12996.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2017-10] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2017-10.parquet... OK\n",
      "    Filas descargadas: 9,768,672\n",
      "    [CLEAN] Filas iniciales: 9,768,672\n",
      "    [CLEAN] Filas válidas: 9,520,431 (248,241 removidas, 2.54%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 9,520,431 filas insertadas \n",
      "         (248,241 removidas, 2.54%) en 241.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o13413.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2017-11] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2017-11.parquet... OK\n",
      "    Filas descargadas: 9,284,803\n",
      "    [CLEAN] Filas iniciales: 9,284,803\n",
      "    [CLEAN] Filas válidas: 9,024,459 (260,344 removidas, 2.80%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 9,024,459 filas insertadas \n",
      "         (260,344 removidas, 2.80%) en 240.4s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o13830.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2017-12] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2017-12.parquet... OK\n",
      "    Filas descargadas: 9,508,501\n",
      "    [CLEAN] Filas iniciales: 9,508,501\n",
      "    [CLEAN] Filas válidas: 9,226,656 (281,845 removidas, 2.96%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 9,226,656 filas insertadas \n",
      "         (281,845 removidas, 2.96%) en 289.0s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o14247.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2018-01] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2018-01.parquet... OK\n",
      "    Filas descargadas: 8,760,687\n",
      "    [CLEAN] Filas iniciales: 8,760,687\n",
      "    [CLEAN] Filas válidas: 8,506,645 (254,042 removidas, 2.90%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 8,506,645 filas insertadas \n",
      "         (254,042 removidas, 2.90%) en 236.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o14664.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2018-02] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2018-02.parquet... OK\n",
      "    Filas descargadas: 8,492,819\n",
      "    [CLEAN] Filas iniciales: 8,492,819\n",
      "    [CLEAN] Filas válidas: 8,265,651 (227,168 removidas, 2.67%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 8,265,651 filas insertadas \n",
      "         (227,168 removidas, 2.67%) en 226.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o15081.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2018-03] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2018-03.parquet... OK\n",
      "    Filas descargadas: 9,431,289\n",
      "    [CLEAN] Filas iniciales: 9,431,289\n",
      "    [CLEAN] Filas válidas: 9,162,836 (268,453 removidas, 2.85%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 9,162,836 filas insertadas \n",
      "         (268,453 removidas, 2.85%) en 289.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o15498.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2018-04] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2018-04.parquet... OK\n",
      "    Filas descargadas: 9,306,216\n",
      "    [CLEAN] Filas iniciales: 9,306,216\n",
      "    [CLEAN] Filas válidas: 9,054,662 (251,554 removidas, 2.70%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 9,054,662 filas insertadas \n",
      "         (251,554 removidas, 2.70%) en 250.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o15915.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2018-05] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2018-05.parquet... OK\n",
      "    Filas descargadas: 9,224,788\n",
      "    [CLEAN] Filas iniciales: 9,224,788\n",
      "    [CLEAN] Filas válidas: 8,992,860 (231,928 removidas, 2.51%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 8,992,860 filas insertadas \n",
      "         (231,928 removidas, 2.51%) en 244.5s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o16332.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2018-06] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2018-06.parquet... OK\n",
      "    Filas descargadas: 8,714,667\n",
      "    [CLEAN] Filas iniciales: 8,714,667\n",
      "    [CLEAN] Filas válidas: 8,484,946 (229,721 removidas, 2.64%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 8,484,946 filas insertadas \n",
      "         (229,721 removidas, 2.64%) en 223.4s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o16749.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2018-07] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2018-07.parquet... OK\n",
      "    Filas descargadas: 7,851,143\n",
      "    [CLEAN] Filas iniciales: 7,851,143\n",
      "    [CLEAN] Filas válidas: 7,636,227 (214,916 removidas, 2.74%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 7,636,227 filas insertadas \n",
      "         (214,916 removidas, 2.74%) en 177.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o17166.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2018-08] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2018-08.parquet... OK\n",
      "    Filas descargadas: 7,855,040\n",
      "    [CLEAN] Filas iniciales: 7,855,040\n",
      "    [CLEAN] Filas válidas: 7,644,186 (210,854 removidas, 2.68%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 7,644,186 filas insertadas \n",
      "         (210,854 removidas, 2.68%) en 184.0s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o17583.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2018-09] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2018-09.parquet... OK\n",
      "    Filas descargadas: 8,049,094\n",
      "    [CLEAN] Filas iniciales: 8,049,094\n",
      "    [CLEAN] Filas válidas: 7,831,596 (217,498 removidas, 2.70%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 7,831,596 filas insertadas \n",
      "         (217,498 removidas, 2.70%) en 176.6s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o18000.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2018-10] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2018-10.parquet... OK\n",
      "    Filas descargadas: 8,834,520\n",
      "    [CLEAN] Filas iniciales: 8,834,520\n",
      "    [CLEAN] Filas válidas: 8,560,239 (274,281 removidas, 3.10%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 8,560,239 filas insertadas \n",
      "         (274,281 removidas, 3.10%) en 205.4s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o18417.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2018-11] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2018-11.parquet... OK\n",
      "    Filas descargadas: 8,155,449\n",
      "    [CLEAN] Filas iniciales: 8,155,449\n",
      "    [CLEAN] Filas válidas: 7,891,754 (263,695 removidas, 3.23%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 7,891,754 filas insertadas \n",
      "         (263,695 removidas, 3.23%) en 210.5s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o18834.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2018-12] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2018-12.parquet... OK\n",
      "    Filas descargadas: 8,195,675\n",
      "    [CLEAN] Filas iniciales: 8,195,675\n",
      "    [CLEAN] Filas válidas: 7,905,825 (289,850 removidas, 3.54%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 7,905,825 filas insertadas \n",
      "         (289,850 removidas, 3.54%) en 200.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o19251.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2019-01] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2019-01.parquet... OK\n",
      "    Filas descargadas: 7,696,617\n",
      "    [CLEAN] Filas iniciales: 7,696,617\n",
      "    [CLEAN] Filas válidas: 7,408,481 (288,136 removidas, 3.74%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 7,408,481 filas insertadas \n",
      "         (288,136 removidas, 3.74%) en 192.9s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o19668.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2019-02] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2019-02.parquet... OK\n",
      "    Filas descargadas: 7,049,370\n",
      "    [CLEAN] Filas iniciales: 7,049,370\n",
      "    [CLEAN] Filas válidas: 6,856,830 (192,540 removidas, 2.73%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 6,856,830 filas insertadas \n",
      "         (192,540 removidas, 2.73%) en 191.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o20085.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2019-03] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2019-03.parquet... OK\n",
      "    Filas descargadas: 7,866,620\n",
      "    [CLEAN] Filas iniciales: 7,866,620\n",
      "    [CLEAN] Filas válidas: 7,675,170 (191,450 removidas, 2.43%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 7,675,170 filas insertadas \n",
      "         (191,450 removidas, 2.43%) en 200.3s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o20502.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2019-04] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2019-04.parquet... OK\n",
      "    Filas descargadas: 7,475,949\n",
      "    [CLEAN] Filas iniciales: 7,475,949\n",
      "    [CLEAN] Filas válidas: 7,263,497 (212,452 removidas, 2.84%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 7,263,497 filas insertadas \n",
      "         (212,452 removidas, 2.84%) en 206.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o20919.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2019-05] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2019-05.parquet... OK\n",
      "    Filas descargadas: 7,598,445\n",
      "    [CLEAN] Filas iniciales: 7,598,445\n",
      "    [CLEAN] Filas válidas: 7,390,753 (207,692 removidas, 2.73%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 7,390,753 filas insertadas \n",
      "         (207,692 removidas, 2.73%) en 220.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o21336.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2019-06] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2019-06.parquet... OK\n",
      "    Filas descargadas: 6,971,560\n",
      "    [CLEAN] Filas iniciales: 6,971,560\n",
      "    [CLEAN] Filas válidas: 6,767,661 (203,899 removidas, 2.92%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 6,767,661 filas insertadas \n",
      "         (203,899 removidas, 2.92%) en 159.1s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o21753.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2019-07] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2019-07.parquet... OK\n",
      "    Filas descargadas: 6,310,419\n",
      "    [CLEAN] Filas iniciales: 6,310,419\n",
      "    [CLEAN] Filas válidas: 6,111,093 (199,326 removidas, 3.16%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 6,111,093 filas insertadas \n",
      "         (199,326 removidas, 3.16%) en 148.0s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o22170.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2019-08] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2019-08.parquet... OK\n",
      "    Filas descargadas: 6,073,357\n",
      "    [CLEAN] Filas iniciales: 6,073,357\n",
      "    [CLEAN] Filas válidas: 5,870,373 (202,984 removidas, 3.34%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 5,870,373 filas insertadas \n",
      "         (202,984 removidas, 3.34%) en 185.3s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o22587.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2019-09] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2019-09.parquet... OK\n",
      "    Filas descargadas: 6,567,788\n",
      "    [CLEAN] Filas iniciales: 6,567,788\n",
      "    [CLEAN] Filas válidas: 6,359,334 (208,454 removidas, 3.17%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 6,359,334 filas insertadas \n",
      "         (208,454 removidas, 3.17%) en 191.4s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o23004.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2019-10] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2019-10.parquet... OK\n",
      "    Filas descargadas: 7,213,891\n",
      "    [CLEAN] Filas iniciales: 7,213,891\n",
      "    [CLEAN] Filas válidas: 6,989,985 (223,906 removidas, 3.10%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 6,989,985 filas insertadas \n",
      "         (223,906 removidas, 3.10%) en 237.9s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o23421.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2019-11] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2019-11.parquet... OK\n",
      "    Filas descargadas: 6,878,111\n",
      "    [CLEAN] Filas iniciales: 6,878,111\n",
      "    [CLEAN] Filas válidas: 6,659,650 (218,461 removidas, 3.18%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 6,659,650 filas insertadas \n",
      "         (218,461 removidas, 3.18%) en 223.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o23838.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2019-12] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2019-12.parquet... OK\n",
      "    Filas descargadas: 6,896,317\n",
      "    [CLEAN] Filas iniciales: 6,896,317\n",
      "    [CLEAN] Filas válidas: 6,667,233 (229,084 removidas, 3.32%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 6,667,233 filas insertadas \n",
      "         (229,084 removidas, 3.32%) en 326.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o24255.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2020-01] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2020-01.parquet... OK\n",
      "    Filas descargadas: 6,405,008\n",
      "    [CLEAN] Filas iniciales: 6,405,008\n",
      "    [CLEAN] Filas válidas: 6,177,335 (227,673 removidas, 3.55%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 6,177,335 filas insertadas \n",
      "         (227,673 removidas, 3.55%) en 300.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o24672.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2020-02] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2020-02.parquet... OK\n",
      "    Filas descargadas: 6,299,367\n",
      "    [CLEAN] Filas iniciales: 6,299,367\n",
      "    [CLEAN] Filas válidas: 6,100,330 (199,037 removidas, 3.16%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 6,100,330 filas insertadas \n",
      "         (199,037 removidas, 3.16%) en 298.9s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o25089.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2020-03] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2020-03.parquet... OK\n",
      "    Filas descargadas: 3,007,687\n",
      "    [CLEAN] Filas iniciales: 3,007,687\n",
      "    [CLEAN] Filas válidas: 2,893,177 (114,510 removidas, 3.81%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,893,177 filas insertadas \n",
      "         (114,510 removidas, 3.81%) en 173.9s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o25506.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2020-04] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2020-04.parquet... OK\n",
      "    Filas descargadas: 238,073\n",
      "    [CLEAN] Filas iniciales: 238,073\n",
      "    [CLEAN] Filas válidas: 207,826 (30,247 removidas, 12.70%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 207,826 filas insertadas \n",
      "         (30,247 removidas, 12.70%) en 16.5s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o25923.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2020-05] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2020-05.parquet... OK\n",
      "    Filas descargadas: 348,415\n",
      "    [CLEAN] Filas iniciales: 348,415\n",
      "    [CLEAN] Filas válidas: 273,802 (74,613 removidas, 21.41%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 273,802 filas insertadas \n",
      "         (74,613 removidas, 21.41%) en 31.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o26340.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2020-06] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2020-06.parquet... OK\n",
      "    Filas descargadas: 549,797\n",
      "    [CLEAN] Filas iniciales: 549,797\n",
      "    [CLEAN] Filas válidas: 472,498 (77,299 removidas, 14.06%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 472,498 filas insertadas \n",
      "         (77,299 removidas, 14.06%) en 31.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o26757.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2020-07] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2020-07.parquet... OK\n",
      "    Filas descargadas: 800,412\n",
      "    [CLEAN] Filas iniciales: 800,412\n",
      "    [CLEAN] Filas válidas: 698,295 (102,117 removidas, 12.76%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 698,295 filas insertadas \n",
      "         (102,117 removidas, 12.76%) en 64.1s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o27174.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2020-08] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2020-08.parquet... OK\n",
      "    Filas descargadas: 1,007,286\n",
      "    [CLEAN] Filas iniciales: 1,007,286\n",
      "    [CLEAN] Filas válidas: 891,900 (115,386 removidas, 11.46%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 891,900 filas insertadas \n",
      "         (115,386 removidas, 11.46%) en 105.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o27591.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2020-09] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2020-09.parquet... OK\n",
      "    Filas descargadas: 1,341,017\n",
      "    [CLEAN] Filas iniciales: 1,341,017\n",
      "    [CLEAN] Filas válidas: 1,207,762 (133,255 removidas, 9.94%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 1,207,762 filas insertadas \n",
      "         (133,255 removidas, 9.94%) en 66.3s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o28008.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2020-10] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2020-10.parquet... OK\n",
      "    Filas descargadas: 1,681,132\n",
      "    [CLEAN] Filas iniciales: 1,681,132\n",
      "    [CLEAN] Filas válidas: 1,526,700 (154,432 removidas, 9.19%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 1,526,700 filas insertadas \n",
      "         (154,432 removidas, 9.19%) en 78.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o28425.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2020-11] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2020-11.parquet... OK\n",
      "    Filas descargadas: 1,509,000\n",
      "    [CLEAN] Filas iniciales: 1,509,000\n",
      "    [CLEAN] Filas válidas: 1,367,365 (141,635 removidas, 9.39%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 1,367,365 filas insertadas \n",
      "         (141,635 removidas, 9.39%) en 62.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o28842.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2020-12] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2020-12.parquet... OK\n",
      "    Filas descargadas: 1,461,898\n",
      "    [CLEAN] Filas iniciales: 1,461,898\n",
      "    [CLEAN] Filas válidas: 1,321,258 (140,640 removidas, 9.62%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 1,321,258 filas insertadas \n",
      "         (140,640 removidas, 9.62%) en 78.5s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o29259.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2021-01] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2021-01.parquet... OK\n",
      "    Filas descargadas: 1,369,769\n",
      "    [CLEAN] Filas iniciales: 1,369,769\n",
      "    [CLEAN] Filas válidas: 1,227,847 (141,922 removidas, 10.36%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 1,227,847 filas insertadas \n",
      "         (141,922 removidas, 10.36%) en 69.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o29676.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2021-02] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2021-02.parquet... OK\n",
      "    Filas descargadas: 1,371,709\n",
      "    [CLEAN] Filas iniciales: 1,371,709\n",
      "    [CLEAN] Filas válidas: 1,232,207 (139,502 removidas, 10.17%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 1,232,207 filas insertadas \n",
      "         (139,502 removidas, 10.17%) en 74.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o30093.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2021-03] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2021-03.parquet... OK\n",
      "    Filas descargadas: 1,925,152\n",
      "    [CLEAN] Filas iniciales: 1,925,152\n",
      "    [CLEAN] Filas válidas: 1,741,619 (183,533 removidas, 9.53%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 1,741,619 filas insertadas \n",
      "         (183,533 removidas, 9.53%) en 92.4s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o30510.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2021-04] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2021-04.parquet... OK\n",
      "    Filas descargadas: 2,171,187\n",
      "    [CLEAN] Filas iniciales: 2,171,187\n",
      "    [CLEAN] Filas válidas: 1,976,251 (194,936 removidas, 8.98%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 1,976,251 filas insertadas \n",
      "         (194,936 removidas, 8.98%) en 112.6s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o30927.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2021-05] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2021-05.parquet... OK\n",
      "    Filas descargadas: 2,507,109\n",
      "    [CLEAN] Filas iniciales: 2,507,109\n",
      "    [CLEAN] Filas válidas: 2,308,790 (198,319 removidas, 7.91%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,308,790 filas insertadas \n",
      "         (198,319 removidas, 7.91%) en 119.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o31344.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2021-06] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2021-06.parquet... OK\n",
      "    Filas descargadas: 2,834,264\n",
      "    [CLEAN] Filas iniciales: 2,834,264\n",
      "    [CLEAN] Filas válidas: 2,632,793 (201,471 removidas, 7.11%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,632,793 filas insertadas \n",
      "         (201,471 removidas, 7.11%) en 135.4s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o31761.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2021-07] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2021-07.parquet... OK\n",
      "    Filas descargadas: 2,821,746\n",
      "    [CLEAN] Filas iniciales: 2,821,746\n",
      "    [CLEAN] Filas válidas: 2,605,735 (216,011 removidas, 7.66%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,605,735 filas insertadas \n",
      "         (216,011 removidas, 7.66%) en 131.6s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o32178.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2021-08] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2021-08.parquet... OK\n",
      "    Filas descargadas: 2,788,757\n",
      "    [CLEAN] Filas iniciales: 2,788,757\n",
      "    [CLEAN] Filas válidas: 2,566,756 (222,001 removidas, 7.96%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,566,756 filas insertadas \n",
      "         (222,001 removidas, 7.96%) en 121.5s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o32595.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2021-09] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2021-09.parquet... OK\n",
      "    Filas descargadas: 2,963,793\n",
      "    [CLEAN] Filas iniciales: 2,963,793\n",
      "    [CLEAN] Filas válidas: 2,717,311 (246,482 removidas, 8.32%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,717,311 filas insertadas \n",
      "         (246,482 removidas, 8.32%) en 223.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o33012.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2021-10] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2021-10.parquet... OK\n",
      "    Filas descargadas: 3,463,504\n",
      "    [CLEAN] Filas iniciales: 3,463,504\n",
      "    [CLEAN] Filas válidas: 3,224,818 (238,686 removidas, 6.89%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,224,818 filas insertadas \n",
      "         (238,686 removidas, 6.89%) en 140.1s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o33429.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2021-11] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2021-11.parquet... OK\n",
      "    Filas descargadas: 3,472,949\n",
      "    [CLEAN] Filas iniciales: 3,472,949\n",
      "    [CLEAN] Filas válidas: 3,244,882 (228,067 removidas, 6.57%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,244,882 filas insertadas \n",
      "         (228,067 removidas, 6.57%) en 105.4s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o33846.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2021-12] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2021-12.parquet... OK\n",
      "    Filas descargadas: 3,214,369\n",
      "    [CLEAN] Filas iniciales: 3,214,369\n",
      "    [CLEAN] Filas válidas: 3,009,139 (205,230 removidas, 6.38%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,009,139 filas insertadas \n",
      "         (205,230 removidas, 6.38%) en 109.1s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o34263.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2022-01] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2022-01.parquet... OK\n",
      "    Filas descargadas: 2,463,931\n",
      "    [CLEAN] Filas iniciales: 2,463,931\n",
      "    [CLEAN] Filas válidas: 2,312,786 (151,145 removidas, 6.13%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,312,786 filas insertadas \n",
      "         (151,145 removidas, 6.13%) en 68.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o34680.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2022-02] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2022-02.parquet... OK\n",
      "    Filas descargadas: 2,979,431\n",
      "    [CLEAN] Filas iniciales: 2,979,431\n",
      "    [CLEAN] Filas válidas: 2,787,584 (191,847 removidas, 6.44%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,787,584 filas insertadas \n",
      "         (191,847 removidas, 6.44%) en 75.5s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o35097.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2022-03] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2022-03.parquet... OK\n",
      "    Filas descargadas: 3,627,882\n",
      "    [CLEAN] Filas iniciales: 3,627,882\n",
      "    [CLEAN] Filas válidas: 3,392,631 (235,251 removidas, 6.48%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,392,631 filas insertadas \n",
      "         (235,251 removidas, 6.48%) en 144.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o35514.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2022-04] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2022-04.parquet... OK\n",
      "    Filas descargadas: 3,599,920\n",
      "    [CLEAN] Filas iniciales: 3,599,920\n",
      "    [CLEAN] Filas válidas: 3,363,321 (236,599 removidas, 6.57%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,363,321 filas insertadas \n",
      "         (236,599 removidas, 6.57%) en 91.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o35931.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2022-05] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2022-05.parquet... OK\n",
      "    Filas descargadas: 3,588,295\n",
      "    [CLEAN] Filas iniciales: 3,588,295\n",
      "    [CLEAN] Filas válidas: 3,333,963 (254,332 removidas, 7.09%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,333,963 filas insertadas \n",
      "         (254,332 removidas, 7.09%) en 92.3s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o36348.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2022-06] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2022-06.parquet... OK\n",
      "    Filas descargadas: 3,558,124\n",
      "    [CLEAN] Filas iniciales: 3,558,124\n",
      "    [CLEAN] Filas válidas: 3,295,708 (262,416 removidas, 7.38%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,295,708 filas insertadas \n",
      "         (262,416 removidas, 7.38%) en 117.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o36765.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2022-07] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2022-07.parquet... OK\n",
      "    Filas descargadas: 3,174,394\n",
      "    [CLEAN] Filas iniciales: 3,174,394\n",
      "    [CLEAN] Filas válidas: 2,948,628 (225,766 removidas, 7.11%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,948,628 filas insertadas \n",
      "         (225,766 removidas, 7.11%) en 81.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o37182.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2022-08] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2022-08.parquet... OK\n",
      "    Filas descargadas: 3,152,677\n",
      "    [CLEAN] Filas iniciales: 3,152,677\n",
      "    [CLEAN] Filas válidas: 2,932,369 (220,308 removidas, 6.99%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,932,369 filas insertadas \n",
      "         (220,308 removidas, 6.99%) en 89.9s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o37599.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2022-09] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2022-09.parquet... OK\n",
      "    Filas descargadas: 3,183,767\n",
      "    [CLEAN] Filas iniciales: 3,183,767\n",
      "    [CLEAN] Filas válidas: 2,935,827 (247,940 removidas, 7.79%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,935,827 filas insertadas \n",
      "         (247,940 removidas, 7.79%) en 99.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o38016.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2022-10] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2022-10.parquet... OK\n",
      "    Filas descargadas: 3,675,411\n",
      "    [CLEAN] Filas iniciales: 3,675,411\n",
      "    [CLEAN] Filas válidas: 3,394,884 (280,527 removidas, 7.63%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,394,884 filas insertadas \n",
      "         (280,527 removidas, 7.63%) en 108.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o38433.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2022-11] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2022-11.parquet... OK\n",
      "    Filas descargadas: 3,252,717\n",
      "    [CLEAN] Filas iniciales: 3,252,717\n",
      "    [CLEAN] Filas válidas: 2,997,003 (255,714 removidas, 7.86%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,997,003 filas insertadas \n",
      "         (255,714 removidas, 7.86%) en 94.6s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o38850.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2022-12] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2022-12.parquet... OK\n",
      "    Filas descargadas: 3,399,549\n",
      "    [CLEAN] Filas iniciales: 3,399,549\n",
      "    [CLEAN] Filas válidas: 3,123,260 (276,289 removidas, 8.13%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,123,260 filas insertadas \n",
      "         (276,289 removidas, 8.13%) en 112.5s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o39267.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2023-01] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2023-01.parquet... OK\n",
      "    Filas descargadas: 3,066,766\n",
      "    [CLEAN] Filas iniciales: 3,066,766\n",
      "    [CLEAN] Filas válidas: 2,873,817 (192,949 removidas, 6.29%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,873,817 filas insertadas \n",
      "         (192,949 removidas, 6.29%) en 77.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o39684.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2023-02] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2023-02.parquet... OK\n",
      "    Filas descargadas: 2,913,955\n",
      "    [CLEAN] Filas iniciales: 2,913,955\n",
      "    [CLEAN] Filas válidas: 2,724,425 (189,530 removidas, 6.50%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,724,425 filas insertadas \n",
      "         (189,530 removidas, 6.50%) en 93.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o40080.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2023-03] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2023-03.parquet... OK\n",
      "    Filas descargadas: 3,403,766\n",
      "    [CLEAN] Filas iniciales: 3,403,766\n",
      "    [CLEAN] Filas válidas: 3,192,732 (211,034 removidas, 6.20%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,192,732 filas insertadas \n",
      "         (211,034 removidas, 6.20%) en 78.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o40476.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2023-04] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2023-04.parquet... OK\n",
      "    Filas descargadas: 3,288,250\n",
      "    [CLEAN] Filas iniciales: 3,288,250\n",
      "    [CLEAN] Filas válidas: 3,076,482 (211,768 removidas, 6.44%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,076,482 filas insertadas \n",
      "         (211,768 removidas, 6.44%) en 78.0s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o40872.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2023-05] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2023-05.parquet... OK\n",
      "    Filas descargadas: 3,513,649\n",
      "    [CLEAN] Filas iniciales: 3,513,649\n",
      "    [CLEAN] Filas válidas: 3,279,419 (234,230 removidas, 6.67%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,279,419 filas insertadas \n",
      "         (234,230 removidas, 6.67%) en 92.9s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o41268.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2023-06] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2023-06.parquet... OK\n",
      "    Filas descargadas: 3,307,234\n",
      "    [CLEAN] Filas iniciales: 3,307,234\n",
      "    [CLEAN] Filas válidas: 3,080,042 (227,192 removidas, 6.87%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,080,042 filas insertadas \n",
      "         (227,192 removidas, 6.87%) en 86.5s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o41664.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2023-07] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2023-07.parquet... OK\n",
      "    Filas descargadas: 2,907,108\n",
      "    [CLEAN] Filas iniciales: 2,907,108\n",
      "    [CLEAN] Filas válidas: 2,702,001 (205,107 removidas, 7.06%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,702,001 filas insertadas \n",
      "         (205,107 removidas, 7.06%) en 69.4s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o42060.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2023-08] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2023-08.parquet... OK\n",
      "    Filas descargadas: 2,824,209\n",
      "    [CLEAN] Filas iniciales: 2,824,209\n",
      "    [CLEAN] Filas válidas: 2,619,820 (204,389 removidas, 7.24%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,619,820 filas insertadas \n",
      "         (204,389 removidas, 7.24%) en 66.9s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o42456.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2023-09] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2023-09.parquet... OK\n",
      "    Filas descargadas: 2,846,722\n",
      "    [CLEAN] Filas iniciales: 2,846,722\n",
      "    [CLEAN] Filas válidas: 2,593,952 (252,770 removidas, 8.88%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,593,952 filas insertadas \n",
      "         (252,770 removidas, 8.88%) en 54.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o42852.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2023-10] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2023-10.parquet... OK\n",
      "    Filas descargadas: 3,522,285\n",
      "    [CLEAN] Filas iniciales: 3,522,285\n",
      "    [CLEAN] Filas válidas: 3,232,574 (289,711 removidas, 8.23%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,232,574 filas insertadas \n",
      "         (289,711 removidas, 8.23%) en 67.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o43248.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2023-11] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2023-11.parquet... OK\n",
      "    Filas descargadas: 3,339,715\n",
      "    [CLEAN] Filas iniciales: 3,339,715\n",
      "    [CLEAN] Filas válidas: 3,081,081 (258,634 removidas, 7.74%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,081,081 filas insertadas \n",
      "         (258,634 removidas, 7.74%) en 50.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o43644.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2023-12] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2023-12.parquet... OK\n",
      "    Filas descargadas: 3,376,567\n",
      "    [CLEAN] Filas iniciales: 3,376,567\n",
      "    [CLEAN] Filas válidas: 3,074,782 (301,785 removidas, 8.94%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,074,782 filas insertadas \n",
      "         (301,785 removidas, 8.94%) en 46.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o44040.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2024-01] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2024-01.parquet... OK\n",
      "    Filas descargadas: 2,964,624\n",
      "    [CLEAN] Filas iniciales: 2,964,624\n",
      "    [CLEAN] Filas válidas: 2,718,966 (245,658 removidas, 8.29%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,718,966 filas insertadas \n",
      "         (245,658 removidas, 8.29%) en 43.0s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o44436.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2024-02] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2024-02.parquet... OK\n",
      "    Filas descargadas: 3,007,526\n",
      "    [CLEAN] Filas iniciales: 3,007,526\n",
      "    [CLEAN] Filas válidas: 2,719,491 (288,035 removidas, 9.58%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,719,491 filas insertadas \n",
      "         (288,035 removidas, 9.58%) en 43.9s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o44832.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2024-03] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2024-03.parquet... OK\n",
      "    Filas descargadas: 3,582,628\n",
      "    [CLEAN] Filas iniciales: 3,582,628\n",
      "    [CLEAN] Filas válidas: 3,035,147 (547,481 removidas, 15.28%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,035,147 filas insertadas \n",
      "         (547,481 removidas, 15.28%) en 55.5s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o45228.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2024-04] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2024-04.parquet... OK\n",
      "    Filas descargadas: 3,514,289\n",
      "    [CLEAN] Filas iniciales: 3,514,289\n",
      "    [CLEAN] Filas válidas: 2,985,758 (528,531 removidas, 15.04%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,985,758 filas insertadas \n",
      "         (528,531 removidas, 15.04%) en 54.0s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o45624.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2024-05] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2024-05.parquet... OK\n",
      "    Filas descargadas: 3,723,833\n",
      "    [CLEAN] Filas iniciales: 3,723,833\n",
      "    [CLEAN] Filas válidas: 3,187,194 (536,639 removidas, 14.41%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,187,194 filas insertadas \n",
      "         (536,639 removidas, 14.41%) en 79.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o46020.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2024-06] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2024-06.parquet... OK\n",
      "    Filas descargadas: 3,539,193\n",
      "    [CLEAN] Filas iniciales: 3,539,193\n",
      "    [CLEAN] Filas válidas: 2,997,717 (541,476 removidas, 15.30%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,997,717 filas insertadas \n",
      "         (541,476 removidas, 15.30%) en 65.6s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o46416.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2024-07] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2024-07.parquet... OK\n",
      "    Filas descargadas: 3,076,903\n",
      "    [CLEAN] Filas iniciales: 3,076,903\n",
      "    [CLEAN] Filas válidas: 2,670,378 (406,525 removidas, 13.21%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,670,378 filas insertadas \n",
      "         (406,525 removidas, 13.21%) en 54.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o46812.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2024-08] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2024-08.parquet... OK\n",
      "    Filas descargadas: 2,979,183\n",
      "    [CLEAN] Filas iniciales: 2,979,183\n",
      "    [CLEAN] Filas válidas: 2,589,720 (389,463 removidas, 13.07%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 2,589,720 filas insertadas \n",
      "         (389,463 removidas, 13.07%) en 55.8s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o47208.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2024-09] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2024-09.parquet... OK\n",
      "    Filas descargadas: 3,633,030\n",
      "    [CLEAN] Filas iniciales: 3,633,030\n",
      "    [CLEAN] Filas válidas: 3,012,311 (620,719 removidas, 17.09%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,012,311 filas insertadas \n",
      "         (620,719 removidas, 17.09%) en 62.1s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o47604.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2024-10] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2024-10.parquet... OK\n",
      "    Filas descargadas: 3,833,771\n",
      "    [CLEAN] Filas iniciales: 3,833,771\n",
      "    [CLEAN] Filas válidas: 3,288,066 (545,705 removidas, 14.23%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,288,066 filas insertadas \n",
      "         (545,705 removidas, 14.23%) en 59.0s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o48000.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2024-11] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2024-11.parquet... OK\n",
      "    Filas descargadas: 3,646,369\n",
      "    [CLEAN] Filas iniciales: 3,646,369\n",
      "    [CLEAN] Filas válidas: 3,134,670 (511,699 removidas, 14.03%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,134,670 filas insertadas \n",
      "         (511,699 removidas, 14.03%) en 42.2s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o48396.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2024-12] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2024-12.parquet... OK\n",
      "    Filas descargadas: 3,668,371\n",
      "    [CLEAN] Filas iniciales: 3,668,371\n",
      "    [CLEAN] Filas válidas: 3,187,772 (480,599 removidas, 13.10%)\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,187,772 filas insertadas \n",
      "         (480,599 removidas, 13.10%) en 49.7s\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o48792.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2025-01] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2025-01.parquet... OK\n",
      "    Filas descargadas: 3,475,226\n",
      "    [CLEAN] Filas iniciales: 3,475,226\n",
      "    [CLEAN] Filas válidas: 2,805,782 (669,444 removidas, 19.26%)\n",
      "    Escribiendo a raw.yellow_taxi_trip...     [ERROR] Column cbd_congestion_fee not found in schema Some(StructType(StructField(VendorID,LongType,true),StructField(tpep_pickup_datetime,TimestampType,true),StructField(tpep_dropoff_datetime,TimestampType,true),StructField(passenger_count,LongType,true),StructField(trip_distance,DoubleType,true),StructField(RatecodeID,LongType,true),StructField(store_and_fwd_flag,StringType,true),StructField(PULocationID,LongType,true),StructField(DOLocationID,LongType,true),StructField(payment_type,LongType,true),StructField(fare_amount,DoubleType,true),StructField(extra,DoubleType,true),StructField(mta_tax,DoubleType,true),StructField(tip_amount,DoubleType,true),StructField(tolls_amount,DoubleType,true),StructField(improvement_surcharge,DoubleType,true),StructField(total_amount,DoubleType,true),StructField(congestion_surcharge,IntegerType,true),StructField(airport_fee,IntegerType,true),StructField(pickup_datetime,TimestampType,true),StructField(dropoff_datetime,TimestampType,true),StructField(service_type,StringType,false),StructField(run_id,StringType,false),StructField(source_year,IntegerType,false),StructField(source_month,IntegerType,false),StructField(ingested_at_utc,StringType,false))).\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o49191.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2025-02] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2025-02.parquet... OK\n",
      "    Filas descargadas: 3,577,543\n",
      "    [CLEAN] Filas iniciales: 3,577,543\n",
      "    [CLEAN] Filas válidas: 2,648,060 (929,483 removidas, 25.98%)\n",
      "    Escribiendo a raw.yellow_taxi_trip...     [ERROR] Column cbd_congestion_fee not found in schema Some(StructType(StructField(VendorID,LongType,true),StructField(tpep_pickup_datetime,TimestampType,true),StructField(tpep_dropoff_datetime,TimestampType,true),StructField(passenger_count,LongType,true),StructField(trip_distance,DoubleType,true),StructField(RatecodeID,LongType,true),StructField(store_and_fwd_flag,StringType,true),StructField(PULocationID,LongType,true),StructField(DOLocationID,LongType,true),StructField(payment_type,LongType,true),StructField(fare_amount,DoubleType,true),StructField(extra,DoubleType,true),StructField(mta_tax,DoubleType,true),StructField(tip_amount,DoubleType,true),StructField(tolls_amount,DoubleType,true),StructField(improvement_surcharge,DoubleType,true),StructField(total_amount,DoubleType,true),StructField(congestion_surcharge,IntegerType,true),StructField(airport_fee,IntegerType,true),StructField(pickup_datetime,TimestampType,true),StructField(dropoff_datetime,TimestampType,true),StructField(service_type,StringType,false),StructField(run_id,StringType,false),StructField(source_year,IntegerType,false),StructField(source_month,IntegerType,false),StructField(ingested_at_utc,StringType,false))).\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o49590.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2025-03] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2025-03.parquet... OK\n",
      "    Filas descargadas: 4,145,257\n",
      "    [CLEAN] Filas iniciales: 4,145,257\n",
      "    [CLEAN] Filas válidas: 3,066,719 (1,078,538 removidas, 26.02%)\n",
      "    Escribiendo a raw.yellow_taxi_trip...     [ERROR] Column cbd_congestion_fee not found in schema Some(StructType(StructField(VendorID,LongType,true),StructField(tpep_pickup_datetime,TimestampType,true),StructField(tpep_dropoff_datetime,TimestampType,true),StructField(passenger_count,LongType,true),StructField(trip_distance,DoubleType,true),StructField(RatecodeID,LongType,true),StructField(store_and_fwd_flag,StringType,true),StructField(PULocationID,LongType,true),StructField(DOLocationID,LongType,true),StructField(payment_type,LongType,true),StructField(fare_amount,DoubleType,true),StructField(extra,DoubleType,true),StructField(mta_tax,DoubleType,true),StructField(tip_amount,DoubleType,true),StructField(tolls_amount,DoubleType,true),StructField(improvement_surcharge,DoubleType,true),StructField(total_amount,DoubleType,true),StructField(congestion_surcharge,IntegerType,true),StructField(airport_fee,IntegerType,true),StructField(pickup_datetime,TimestampType,true),StructField(dropoff_datetime,TimestampType,true),StructField(service_type,StringType,false),StructField(run_id,StringType,false),StructField(source_year,IntegerType,false),StructField(source_month,IntegerType,false),StructField(ingested_at_utc,StringType,false))).\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o49989.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2025-04] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2025-04.parquet... OK\n",
      "    Filas descargadas: 3,970,553\n",
      "    [CLEAN] Filas iniciales: 3,970,553\n",
      "    [CLEAN] Filas válidas: 3,045,743 (924,810 removidas, 23.29%)\n",
      "    Escribiendo a raw.yellow_taxi_trip...     [ERROR] Column cbd_congestion_fee not found in schema Some(StructType(StructField(VendorID,LongType,true),StructField(tpep_pickup_datetime,TimestampType,true),StructField(tpep_dropoff_datetime,TimestampType,true),StructField(passenger_count,LongType,true),StructField(trip_distance,DoubleType,true),StructField(RatecodeID,LongType,true),StructField(store_and_fwd_flag,StringType,true),StructField(PULocationID,LongType,true),StructField(DOLocationID,LongType,true),StructField(payment_type,LongType,true),StructField(fare_amount,DoubleType,true),StructField(extra,DoubleType,true),StructField(mta_tax,DoubleType,true),StructField(tip_amount,DoubleType,true),StructField(tolls_amount,DoubleType,true),StructField(improvement_surcharge,DoubleType,true),StructField(total_amount,DoubleType,true),StructField(congestion_surcharge,IntegerType,true),StructField(airport_fee,IntegerType,true),StructField(pickup_datetime,TimestampType,true),StructField(dropoff_datetime,TimestampType,true),StructField(service_type,StringType,false),StructField(run_id,StringType,false),StructField(source_year,IntegerType,false),StructField(source_month,IntegerType,false),StructField(ingested_at_utc,StringType,false))).\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o50388.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2025-05] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2025-05.parquet... OK\n",
      "    Filas descargadas: 4,591,845\n",
      "    [CLEAN] Filas iniciales: 4,591,845\n",
      "    [CLEAN] Filas válidas: 3,175,277 (1,416,568 removidas, 30.85%)\n",
      "    Escribiendo a raw.yellow_taxi_trip...     [ERROR] Column cbd_congestion_fee not found in schema Some(StructType(StructField(VendorID,LongType,true),StructField(tpep_pickup_datetime,TimestampType,true),StructField(tpep_dropoff_datetime,TimestampType,true),StructField(passenger_count,LongType,true),StructField(trip_distance,DoubleType,true),StructField(RatecodeID,LongType,true),StructField(store_and_fwd_flag,StringType,true),StructField(PULocationID,LongType,true),StructField(DOLocationID,LongType,true),StructField(payment_type,LongType,true),StructField(fare_amount,DoubleType,true),StructField(extra,DoubleType,true),StructField(mta_tax,DoubleType,true),StructField(tip_amount,DoubleType,true),StructField(tolls_amount,DoubleType,true),StructField(improvement_surcharge,DoubleType,true),StructField(total_amount,DoubleType,true),StructField(congestion_surcharge,IntegerType,true),StructField(airport_fee,IntegerType,true),StructField(pickup_datetime,TimestampType,true),StructField(dropoff_datetime,TimestampType,true),StructField(service_type,StringType,false),StructField(run_id,StringType,false),StructField(source_year,IntegerType,false),StructField(source_month,IntegerType,false),StructField(ingested_at_utc,StringType,false))).\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o50787.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2025-06] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2025-06.parquet... OK\n",
      "    Filas descargadas: 4,322,960\n",
      "    [CLEAN] Filas iniciales: 4,322,960\n",
      "    [CLEAN] Filas válidas: 2,895,550 (1,427,410 removidas, 33.02%)\n",
      "    Escribiendo a raw.yellow_taxi_trip...     [ERROR] Column cbd_congestion_fee not found in schema Some(StructType(StructField(VendorID,LongType,true),StructField(tpep_pickup_datetime,TimestampType,true),StructField(tpep_dropoff_datetime,TimestampType,true),StructField(passenger_count,LongType,true),StructField(trip_distance,DoubleType,true),StructField(RatecodeID,LongType,true),StructField(store_and_fwd_flag,StringType,true),StructField(PULocationID,LongType,true),StructField(DOLocationID,LongType,true),StructField(payment_type,LongType,true),StructField(fare_amount,DoubleType,true),StructField(extra,DoubleType,true),StructField(mta_tax,DoubleType,true),StructField(tip_amount,DoubleType,true),StructField(tolls_amount,DoubleType,true),StructField(improvement_surcharge,DoubleType,true),StructField(total_amount,DoubleType,true),StructField(congestion_surcharge,IntegerType,true),StructField(airport_fee,IntegerType,true),StructField(pickup_datetime,TimestampType,true),StructField(dropoff_datetime,TimestampType,true),StructField(service_type,StringType,false),StructField(run_id,StringType,false),StructField(source_year,IntegerType,false),StructField(source_month,IntegerType,false),StructField(ingested_at_utc,StringType,false))).\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o51186.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2025-07] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2025-07.parquet... OK\n",
      "    Filas descargadas: 3,898,963\n",
      "    [CLEAN] Filas iniciales: 3,898,963\n",
      "    [CLEAN] Filas válidas: 2,658,385 (1,240,578 removidas, 31.82%)\n",
      "    Escribiendo a raw.yellow_taxi_trip...     [ERROR] Column cbd_congestion_fee not found in schema Some(StructType(StructField(VendorID,LongType,true),StructField(tpep_pickup_datetime,TimestampType,true),StructField(tpep_dropoff_datetime,TimestampType,true),StructField(passenger_count,LongType,true),StructField(trip_distance,DoubleType,true),StructField(RatecodeID,LongType,true),StructField(store_and_fwd_flag,StringType,true),StructField(PULocationID,LongType,true),StructField(DOLocationID,LongType,true),StructField(payment_type,LongType,true),StructField(fare_amount,DoubleType,true),StructField(extra,DoubleType,true),StructField(mta_tax,DoubleType,true),StructField(tip_amount,DoubleType,true),StructField(tolls_amount,DoubleType,true),StructField(improvement_surcharge,DoubleType,true),StructField(total_amount,DoubleType,true),StructField(congestion_surcharge,IntegerType,true),StructField(airport_fee,IntegerType,true),StructField(pickup_datetime,TimestampType,true),StructField(dropoff_datetime,TimestampType,true),StructField(service_type,StringType,false),StructField(run_id,StringType,false),StructField(source_year,IntegerType,false),StructField(source_month,IntegerType,false),StructField(ingested_at_utc,StringType,false))).\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o51585.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2025-08] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2025-08.parquet... OK\n",
      "    Filas descargadas: 3,574,091\n",
      "    [CLEAN] Filas iniciales: 3,574,091\n",
      "    [CLEAN] Filas válidas: 2,492,865 (1,081,226 removidas, 30.25%)\n",
      "    Escribiendo a raw.yellow_taxi_trip...     [ERROR] Column cbd_congestion_fee not found in schema Some(StructType(StructField(VendorID,LongType,true),StructField(tpep_pickup_datetime,TimestampType,true),StructField(tpep_dropoff_datetime,TimestampType,true),StructField(passenger_count,LongType,true),StructField(trip_distance,DoubleType,true),StructField(RatecodeID,LongType,true),StructField(store_and_fwd_flag,StringType,true),StructField(PULocationID,LongType,true),StructField(DOLocationID,LongType,true),StructField(payment_type,LongType,true),StructField(fare_amount,DoubleType,true),StructField(extra,DoubleType,true),StructField(mta_tax,DoubleType,true),StructField(tip_amount,DoubleType,true),StructField(tolls_amount,DoubleType,true),StructField(improvement_surcharge,DoubleType,true),StructField(total_amount,DoubleType,true),StructField(congestion_surcharge,IntegerType,true),StructField(airport_fee,IntegerType,true),StructField(pickup_datetime,TimestampType,true),StructField(dropoff_datetime,TimestampType,true),StructField(service_type,StringType,false),StructField(run_id,StringType,false),StructField(source_year,IntegerType,false),StructField(source_month,IntegerType,false),StructField(ingested_at_utc,StringType,false))).\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o51984.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2025-09] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2025-09.parquet... OK\n",
      "    Filas descargadas: 4,251,015\n",
      "    [CLEAN] Filas iniciales: 4,251,015\n",
      "    [CLEAN] Filas válidas: 2,974,079 (1,276,936 removidas, 30.04%)\n",
      "    Escribiendo a raw.yellow_taxi_trip...     [ERROR] Column cbd_congestion_fee not found in schema Some(StructType(StructField(VendorID,LongType,true),StructField(tpep_pickup_datetime,TimestampType,true),StructField(tpep_dropoff_datetime,TimestampType,true),StructField(passenger_count,LongType,true),StructField(trip_distance,DoubleType,true),StructField(RatecodeID,LongType,true),StructField(store_and_fwd_flag,StringType,true),StructField(PULocationID,LongType,true),StructField(DOLocationID,LongType,true),StructField(payment_type,LongType,true),StructField(fare_amount,DoubleType,true),StructField(extra,DoubleType,true),StructField(mta_tax,DoubleType,true),StructField(tip_amount,DoubleType,true),StructField(tolls_amount,DoubleType,true),StructField(improvement_surcharge,DoubleType,true),StructField(total_amount,DoubleType,true),StructField(congestion_surcharge,IntegerType,true),StructField(airport_fee,IntegerType,true),StructField(pickup_datetime,TimestampType,true),StructField(dropoff_datetime,TimestampType,true),StructField(service_type,StringType,false),StructField(run_id,StringType,false),StructField(source_year,IntegerType,false),StructField(source_month,IntegerType,false),StructField(ingested_at_utc,StringType,false))).\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o52383.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2025-10] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2025-10.parquet...     [ERROR] HTTP Error 403: Forbidden\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o52390.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2025-11] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2025-11.parquet...     [ERROR] HTTP Error 403: Forbidden\n",
      "\n",
      "    [WARNING] No se pudo verificar existencia: An error occurred while calling o52397.load.\n",
      ": java.sql.SQLException: No suitable driver\n",
      "\tat java.sql/java.sql.DriverManager.getDriver(DriverManager.java:299)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "[2025-12] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2025-12.parquet...     [ERROR] HTTP Error 403: Forbidden\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RESUMEN YELLOW:\n",
      "  Filas insertadas: 696,203,512\n",
      "  Filas removidas: 30,126,498\n",
      "  Tasa de validez: 95.85%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RESUMEN GLOBAL DE INGESTA\n",
      "================================================================================\n",
      "Total filas insertadas: 696,203,512\n",
      "Total filas removidas: 30,126,498\n",
      "Tasa de validez global: 95.85%\n",
      "Total errores: 14\n",
      "RUN_ID: localtest\n",
      "================================================================================\n",
      "\n",
      "Log de ingesta guardado en variable 'log_df'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import lit, col\n",
    "\n",
    "# Estadísticas globales\n",
    "total_rows = 0\n",
    "total_removed = 0\n",
    "total_errors = 0\n",
    "ingestion_log = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"INICIANDO BACKFILL 2015-2025 CON LIMPIEZA DE DATOS Y VERIFICACIÓN DE EXISTENCIA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def is_already_ingested(service, year, month, table):\n",
    "    \"\"\"\n",
    "    Retorna True si ya hay datos para ese service, año y mes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_check = spark.read \\\n",
    "            .format(\"jdbc\") \\\n",
    "            .option(\"url\", \"admin@postgres:5432/nyc_taxi\") \\\n",
    "            .option(\"dbtable\", table) \\\n",
    "            .option(\"user\", PG_USER) \\\n",
    "            .option(\"password\", PG_PASSWORD) \\\n",
    "            .load() \\\n",
    "            .filter((col(\"service_type\") == service) & (col(\"year\") == year) & (col(\"month\") == month))\n",
    "        \n",
    "        return df_check.count() > 0\n",
    "    except Exception as e:\n",
    "        print(f\"    [WARNING] No se pudo verificar existencia: {e}\")\n",
    "        return False\n",
    "\n",
    "for service in SERVICES:\n",
    "    table = f\"{PG_SCHEMA_RAW}.{service}_taxi_trip\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SERVICIO: {service.upper()} → {table}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    service_rows = 0\n",
    "    service_removed = 0\n",
    "\n",
    "    for y in YEARS:\n",
    "        for m in MONTHS:\n",
    "\n",
    "            # 0) Verificar si ya existe en DB\n",
    "            if is_already_ingested(service, y, m, table):\n",
    "                print(f\"[{y}-{m:02d}] Ya existe en DB → saltando\")\n",
    "                log_entry = {\n",
    "                    'service': service,\n",
    "                    'year': y,\n",
    "                    'month': m,\n",
    "                    'raw_count': 0,\n",
    "                    'clean_count': 0,\n",
    "                    'removed': 0,\n",
    "                    'pct_removed': 0,\n",
    "                    'duration_sec': 0,\n",
    "                    'status': 'SKIPPED'\n",
    "                }\n",
    "                ingestion_log.append(log_entry)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                t0 = time.time()\n",
    "                print(f\"[{y}-{m:02d}] Procesando {service}...\")\n",
    "\n",
    "                # 1) Descargar y leer Parquet\n",
    "                tmp_path = download_to_temp(build_url(service, y, m))\n",
    "                raw_df = spark.read.parquet(tmp_path)\n",
    "                raw_count = raw_df.count()\n",
    "                print(f\"    Filas descargadas: {raw_count:,}\")\n",
    "\n",
    "                # 2) Estandarizar columnas\n",
    "                df = standardize_columns(raw_df, service)\n",
    "\n",
    "                # 3) Limpieza de datos\n",
    "                df_clean = clean_taxi_data(df, service)\n",
    "                clean_count = df_clean.count()\n",
    "                removed = raw_count - clean_count\n",
    "\n",
    "                # 4) Validar que hay datos\n",
    "                if clean_count == 0:\n",
    "                    print(\"    [SKIP] 0 filas después de limpieza\\n\")\n",
    "                    log_entry = {\n",
    "                        'service': service,\n",
    "                        'year': y,\n",
    "                        'month': m,\n",
    "                        'raw_count': raw_count,\n",
    "                        'clean_count': 0,\n",
    "                        'removed': removed,\n",
    "                        'pct_removed': 100.0,\n",
    "                        'duration_sec': time.time() - t0,\n",
    "                        'status': 'SKIPPED'\n",
    "                    }\n",
    "                    ingestion_log.append(log_entry)\n",
    "                    continue\n",
    "\n",
    "                # 5) Agregar metadatos\n",
    "                df_final = add_metadata(df_clean, y, m, RUN_ID)\n",
    "                df_final = df_final.withColumn(\"service_type\", lit(service))  # 'yellow' o 'green'\n",
    "\n",
    "                # 6) Escribir a Postgres\n",
    "                print(f\"    Escribiendo a {table}...\", end=\" \")\n",
    "                write_batch(df_final, table, mode=\"overwrite\", writers=4, batchsize=5000)\n",
    "                print(\"OK\")\n",
    "\n",
    "                # 7) Estadísticas\n",
    "                total_rows += clean_count\n",
    "                total_removed += removed\n",
    "                service_rows += clean_count\n",
    "                service_removed += removed\n",
    "\n",
    "                dt = time.time() - t0\n",
    "                pct_removed = (removed / raw_count * 100) if raw_count > 0 else 0\n",
    "\n",
    "                log_entry = {\n",
    "                    'service': service,\n",
    "                    'year': y,\n",
    "                    'month': m,\n",
    "                    'raw_count': raw_count,\n",
    "                    'clean_count': clean_count,\n",
    "                    'removed': removed,\n",
    "                    'pct_removed': pct_removed,\n",
    "                    'duration_sec': dt,\n",
    "                    'status': 'OK'\n",
    "                }\n",
    "                ingestion_log.append(log_entry)\n",
    "\n",
    "                print(f\"    [OK] {clean_count:,} filas insertadas \")\n",
    "                print(f\"         ({removed:,} removidas, {pct_removed:.2f}%) en {dt:.1f}s\\n\")\n",
    "\n",
    "            except Exception as e:\n",
    "                total_errors += 1\n",
    "                print(f\"    [ERROR] {e}\\n\")\n",
    "                log_entry = {\n",
    "                    'service': service,\n",
    "                    'year': y,\n",
    "                    'month': m,\n",
    "                    'raw_count': 0,\n",
    "                    'clean_count': 0,\n",
    "                    'removed': 0,\n",
    "                    'pct_removed': 0,\n",
    "                    'duration_sec': 0,\n",
    "                    'status': 'ERROR',\n",
    "                    'error': str(e)\n",
    "                }\n",
    "                ingestion_log.append(log_entry)\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RESUMEN {service.upper()}:\")\n",
    "    print(f\"  Filas insertadas: {service_rows:,}\")\n",
    "    print(f\"  Filas removidas: {service_removed:,}\")\n",
    "    if service_rows + service_removed > 0:\n",
    "        pct_valid = service_rows / (service_rows + service_removed) * 100\n",
    "        print(f\"  Tasa de validez: {pct_valid:.2f}%\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN GLOBAL DE INGESTA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total filas insertadas: {total_rows:,}\")\n",
    "print(f\"Total filas removidas: {total_removed:,}\")\n",
    "if total_rows + total_removed > 0:\n",
    "    pct_valid = total_rows / (total_rows + total_removed) * 100\n",
    "    print(f\"Tasa de validez global: {pct_valid:.2f}%\")\n",
    "print(f\"Total errores: {total_errors}\")\n",
    "print(f\"RUN_ID: {RUN_ID}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Convertir log a DataFrame de Pandas para análisis\n",
    "log_df = pd.DataFrame(ingestion_log)\n",
    "print(\"\\nLog de ingesta guardado en variable 'log_df'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837bdebf",
   "metadata": {},
   "source": [
    "## 10. Análisis del log de ingesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54a2304f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESUMEN POR SERVICIO:\n",
      "         raw_count  clean_count   removed  duration_sec\n",
      "service                                                \n",
      "yellow   726330010    696203512  30126498      23694.84\n",
      "\n",
      "\n",
      "RESUMEN POR AÑO:\n",
      "      raw_count  clean_count  removed\n",
      "year                                 \n",
      "2015  119538603    116430747  3107856\n",
      "2016  131131805    127838281  3293524\n",
      "2017  113500327    110474320  3026007\n",
      "2018  102871387     99937427  2933960\n",
      "2019   84598444     82020060  2578384\n",
      "2020   24649092     23138248  1510844\n",
      "2021   30904308     28488148  2416160\n",
      "2022   39656098     36817964  2838134\n",
      "2023   38310226     35531127  2779099\n",
      "2024   41169720     35527190  5642530\n",
      "2025          0            0        0\n",
      "\n",
      "\n",
      "ERRORES (14 archivos):\n",
      "    service  year  month                                              error\n",
      "2    yellow  2015      3  An error occurred while calling o877.parquet.\\...\n",
      "4    yellow  2015      5  An error occurred while calling o1308.parquet....\n",
      "120  yellow  2025      1  Column cbd_congestion_fee not found in schema ...\n",
      "121  yellow  2025      2  Column cbd_congestion_fee not found in schema ...\n",
      "122  yellow  2025      3  Column cbd_congestion_fee not found in schema ...\n",
      "123  yellow  2025      4  Column cbd_congestion_fee not found in schema ...\n",
      "124  yellow  2025      5  Column cbd_congestion_fee not found in schema ...\n",
      "125  yellow  2025      6  Column cbd_congestion_fee not found in schema ...\n",
      "126  yellow  2025      7  Column cbd_congestion_fee not found in schema ...\n",
      "127  yellow  2025      8  Column cbd_congestion_fee not found in schema ...\n",
      "128  yellow  2025      9  Column cbd_congestion_fee not found in schema ...\n",
      "129  yellow  2025     10                          HTTP Error 403: Forbidden\n",
      "130  yellow  2025     11                          HTTP Error 403: Forbidden\n",
      "131  yellow  2025     12                          HTTP Error 403: Forbidden\n"
     ]
    }
   ],
   "source": [
    "# Resumen por servicio\n",
    "print(\"\\nRESUMEN POR SERVICIO:\")\n",
    "if len(log_df) > 0:\n",
    "    print(log_df.groupby('service').agg({\n",
    "        'raw_count': 'sum',\n",
    "        'clean_count': 'sum',\n",
    "        'removed': 'sum',\n",
    "        'duration_sec': 'sum'\n",
    "    }).round(2))\n",
    "else:\n",
    "    print(\"Sin datos en el log.\")\n",
    "\n",
    "# Resumen por año\n",
    "print(\"\\n\\nRESUMEN POR AÑO:\")\n",
    "if len(log_df) > 0:\n",
    "    print(log_df.groupby('year').agg({\n",
    "        'raw_count': 'sum',\n",
    "        'clean_count': 'sum',\n",
    "        'removed': 'sum'\n",
    "    }).round(2))\n",
    "else:\n",
    "    print(\"Sin datos en el log.\")\n",
    "\n",
    "# Errores\n",
    "if len(log_df) > 0:\n",
    "    errors = log_df[log_df['status'] == 'ERROR']\n",
    "    if len(errors) > 0:\n",
    "        print(f\"\\n\\nERRORES ({len(errors)} archivos):\")\n",
    "        print(errors[['service', 'year', 'month', 'error']])\n",
    "    else:\n",
    "        print(\"\\n\\n✓ Sin errores en la ingesta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653caa91",
   "metadata": {},
   "source": [
    "## 11. Ingesta de Taxi Zone Lookup\n",
    "\n",
    "Cargamos el catálogo de zonas que mapea `LocationID` → `zone`, `borough`, `service_zone`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c77c3076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando Taxi Zone Lookup...\n",
      "Zonas cargadas: 265\n",
      "✓ Taxi Zone Lookup insertado en raw.taxi_zone_lookup\n",
      "+----------+-------------+-----------------------+------------+---------+--------------------------+\n",
      "|locationid|borough      |zone                   |service_zone|run_id   |ingested_at_utc           |\n",
      "+----------+-------------+-----------------------+------------+---------+--------------------------+\n",
      "|1         |EWR          |Newark Airport         |EWR         |localtest|2025-11-04 01:57:07.524996|\n",
      "|2         |Queens       |Jamaica Bay            |Boro Zone   |localtest|2025-11-04 01:57:07.524996|\n",
      "|3         |Bronx        |Allerton/Pelham Gardens|Boro Zone   |localtest|2025-11-04 01:57:07.524996|\n",
      "|4         |Manhattan    |Alphabet City          |Yellow Zone |localtest|2025-11-04 01:57:07.524996|\n",
      "|5         |Staten Island|Arden Heights          |Boro Zone   |localtest|2025-11-04 01:57:07.524996|\n",
      "|6         |Staten Island|Arrochar/Fort Wadsworth|Boro Zone   |localtest|2025-11-04 01:57:07.524996|\n",
      "|7         |Queens       |Astoria                |Boro Zone   |localtest|2025-11-04 01:57:07.524996|\n",
      "|8         |Queens       |Astoria Park           |Boro Zone   |localtest|2025-11-04 01:57:07.524996|\n",
      "|9         |Queens       |Auburndale             |Boro Zone   |localtest|2025-11-04 01:57:07.524996|\n",
      "|10        |Queens       |Baisley Park           |Boro Zone   |localtest|2025-11-04 01:57:07.524996|\n",
      "+----------+-------------+-----------------------+------------+---------+--------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from urllib.request import urlretrieve\n",
    "from pyspark.sql.functions import lit, current_timestamp\n",
    "\n",
    "# URL del archivo taxi_zone_lookup\n",
    "ZONE_LOOKUP_URL = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv\"\n",
    "\n",
    "print(\"Descargando Taxi Zone Lookup...\")\n",
    "try:\n",
    "    # Descargar CSV\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    zone_path = os.path.join(temp_dir, \"taxi_zone_lookup.csv\")\n",
    "    urlretrieve(ZONE_LOOKUP_URL, zone_path)\n",
    "\n",
    "    # Leer con Spark\n",
    "    zones_df = spark.read.csv(zone_path, header=True, inferSchema=True)\n",
    "\n",
    "    # Estandarizar nombres de columnas\n",
    "    zones_df = zones_df.toDF(*[c.lower().replace(' ', '_') for c in zones_df.columns])\n",
    "\n",
    "    # Agregar metadatos\n",
    "    zones_df = zones_df.withColumn('run_id', lit(RUN_ID)) \\\n",
    "                       .withColumn('ingested_at_utc', current_timestamp())\n",
    "\n",
    "    # Contar filas\n",
    "    zone_count = zones_df.count()\n",
    "    print(f\"Zonas cargadas: {zone_count}\")\n",
    "\n",
    "    # Escribir a Postgres (overwrite para mantener actualizado)\n",
    "    zones_table = f\"{PG_SCHEMA_RAW}.taxi_zone_lookup\"\n",
    "    write_batch(zones_df, zones_table, mode=\"overwrite\")\n",
    "\n",
    "    print(f\"✓ Taxi Zone Lookup insertado en {zones_table}\")\n",
    "\n",
    "    # Mostrar preview\n",
    "    zones_df.show(10, truncate=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] No se pudo cargar Taxi Zone Lookup: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed73f4aa",
   "metadata": {},
   "source": [
    "## 12. Validación final: Conteos en Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf380c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VALIDACIÓN FINAL: Conteos en Postgres\n",
      "================================================================================\n",
      "\n",
      "raw.yellow_taxi_trip: 708,576,559 filas\n",
      "raw.green_taxi_trip: 68,262,085 filas\n",
      "raw.taxi_zone_lookup: 265 filas\n",
      "\n",
      "TOTAL TRIPS: 776,838,644 filas\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def get_table_count(table_name: str) -> int:\n",
    "    \"\"\"Obtiene el conteo de filas de una tabla en Postgres.\"\"\"\n",
    "    jdbc_url = get_postgres_jdbc_url()\n",
    "    properties = get_postgres_properties()\n",
    "    query = f\"(SELECT COUNT(*) as count FROM {table_name}) as subquery\"\n",
    "    df = spark.read.jdbc(url=jdbc_url, table=query, properties=properties)\n",
    "    return df.collect()[0]['count']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDACIÓN FINAL: Conteos en Postgres\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    yellow_count = get_table_count(f\"{PG_SCHEMA_RAW}.yellow_taxi_trip\")\n",
    "    print(f\"\\n{PG_SCHEMA_RAW}.yellow_taxi_trip: {yellow_count:,} filas\")\n",
    "except Exception as e:\n",
    "    print(f\"Error leyendo yellow_taxi_trip: {e}\")\n",
    "    yellow_count = 0\n",
    "\n",
    "try:\n",
    "    green_count = get_table_count(f\"{PG_SCHEMA_RAW}.green_taxi_trip\")\n",
    "    print(f\"{PG_SCHEMA_RAW}.green_taxi_trip: {green_count:,} filas\")\n",
    "except Exception as e:\n",
    "    print(f\"Error leyendo green_taxi_trip: {e}\")\n",
    "    green_count = 0\n",
    "\n",
    "try:\n",
    "    zones_count = get_table_count(f\"{PG_SCHEMA_RAW}.taxi_zone_lookup\")\n",
    "    print(f\"{PG_SCHEMA_RAW}.taxi_zone_lookup: {zones_count:,} filas\")\n",
    "except Exception as e:\n",
    "    print(f\"Error leyendo taxi_zone_lookup: {e}\")\n",
    "    zones_count = 0\n",
    "\n",
    "print(f\"\\nTOTAL TRIPS: {yellow_count + green_count:,} filas\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc54d7b",
   "metadata": {},
   "source": [
    "## 13. Exploración rápida de los datos cargados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2378f309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MUESTRA: raw.yellow_taxi_trip (primeras 5 filas)\n",
      "================================================================================\n",
      "-RECORD 0----------------------------------------------\n",
      " VendorID              | 1                             \n",
      " tpep_pickup_datetime  | 2015-01-01 00:11:33           \n",
      " tpep_dropoff_datetime | 2015-01-01 00:16:48           \n",
      " passenger_count       | 1                             \n",
      " trip_distance         | 1.0                           \n",
      " RatecodeID            | 1                             \n",
      " store_and_fwd_flag    | N                             \n",
      " PULocationID          | 41                            \n",
      " DOLocationID          | 166                           \n",
      " payment_type          | 1                             \n",
      " fare_amount           | 5.7                           \n",
      " extra                 | 0.5                           \n",
      " mta_tax               | 0.5                           \n",
      " tip_amount            | 1.4                           \n",
      " tolls_amount          | 0.0                           \n",
      " improvement_surcharge | 0.0                           \n",
      " total_amount          | 8.4                           \n",
      " congestion_surcharge  | 0                             \n",
      " airport_fee           | 0                             \n",
      " pickup_datetime       | NULL                          \n",
      " dropoff_datetime      | NULL                          \n",
      " service_type          | yellow                        \n",
      " run_id                | localtest                     \n",
      " source_year           | 2015                          \n",
      " source_month          | 1                             \n",
      " ingested_at_utc       | 2025-11-03 18:37:17.963346+00 \n",
      "-RECORD 1----------------------------------------------\n",
      " VendorID              | 1                             \n",
      " tpep_pickup_datetime  | 2015-01-01 00:18:24           \n",
      " tpep_dropoff_datetime | 2015-01-01 00:24:20           \n",
      " passenger_count       | 1                             \n",
      " trip_distance         | 0.9                           \n",
      " RatecodeID            | 1                             \n",
      " store_and_fwd_flag    | N                             \n",
      " PULocationID          | 166                           \n",
      " DOLocationID          | 238                           \n",
      " payment_type          | 3                             \n",
      " fare_amount           | 6.0                           \n",
      " extra                 | 0.5                           \n",
      " mta_tax               | 0.5                           \n",
      " tip_amount            | 0.0                           \n",
      " tolls_amount          | 0.0                           \n",
      " improvement_surcharge | 0.0                           \n",
      " total_amount          | 7.3                           \n",
      " congestion_surcharge  | 0                             \n",
      " airport_fee           | 0                             \n",
      " pickup_datetime       | NULL                          \n",
      " dropoff_datetime      | NULL                          \n",
      " service_type          | yellow                        \n",
      " run_id                | localtest                     \n",
      " source_year           | 2015                          \n",
      " source_month          | 1                             \n",
      " ingested_at_utc       | 2025-11-03 18:37:17.963346+00 \n",
      "-RECORD 2----------------------------------------------\n",
      " VendorID              | 1                             \n",
      " tpep_pickup_datetime  | 2015-01-01 00:26:19           \n",
      " tpep_dropoff_datetime | 2015-01-01 00:41:06           \n",
      " passenger_count       | 1                             \n",
      " trip_distance         | 3.5                           \n",
      " RatecodeID            | 1                             \n",
      " store_and_fwd_flag    | N                             \n",
      " PULocationID          | 238                           \n",
      " DOLocationID          | 162                           \n",
      " payment_type          | 1                             \n",
      " fare_amount           | 13.2                          \n",
      " extra                 | 0.5                           \n",
      " mta_tax               | 0.5                           \n",
      " tip_amount            | 2.9                           \n",
      " tolls_amount          | 0.0                           \n",
      " improvement_surcharge | 0.0                           \n",
      " total_amount          | 17.4                          \n",
      " congestion_surcharge  | 0                             \n",
      " airport_fee           | 0                             \n",
      " pickup_datetime       | NULL                          \n",
      " dropoff_datetime      | NULL                          \n",
      " service_type          | yellow                        \n",
      " run_id                | localtest                     \n",
      " source_year           | 2015                          \n",
      " source_month          | 1                             \n",
      " ingested_at_utc       | 2025-11-03 18:37:17.963346+00 \n",
      "-RECORD 3----------------------------------------------\n",
      " VendorID              | 1                             \n",
      " tpep_pickup_datetime  | 2015-01-01 00:45:26           \n",
      " tpep_dropoff_datetime | 2015-01-01 00:53:20           \n",
      " passenger_count       | 1                             \n",
      " trip_distance         | 2.1                           \n",
      " RatecodeID            | 1                             \n",
      " store_and_fwd_flag    | N                             \n",
      " PULocationID          | 162                           \n",
      " DOLocationID          | 263                           \n",
      " payment_type          | 1                             \n",
      " fare_amount           | 8.2                           \n",
      " extra                 | 0.5                           \n",
      " mta_tax               | 0.5                           \n",
      " tip_amount            | 2.37                          \n",
      " tolls_amount          | 0.0                           \n",
      " improvement_surcharge | 0.0                           \n",
      " total_amount          | 11.87                         \n",
      " congestion_surcharge  | 0                             \n",
      " airport_fee           | 0                             \n",
      " pickup_datetime       | NULL                          \n",
      " dropoff_datetime      | NULL                          \n",
      " service_type          | yellow                        \n",
      " run_id                | localtest                     \n",
      " source_year           | 2015                          \n",
      " source_month          | 1                             \n",
      " ingested_at_utc       | 2025-11-03 18:37:17.963346+00 \n",
      "-RECORD 4----------------------------------------------\n",
      " VendorID              | 1                             \n",
      " tpep_pickup_datetime  | 2015-01-01 00:59:21           \n",
      " tpep_dropoff_datetime | 2015-01-01 01:05:24           \n",
      " passenger_count       | 1                             \n",
      " trip_distance         | 1.0                           \n",
      " RatecodeID            | 1                             \n",
      " store_and_fwd_flag    | N                             \n",
      " PULocationID          | 236                           \n",
      " DOLocationID          | 141                           \n",
      " payment_type          | 3                             \n",
      " fare_amount           | 6.0                           \n",
      " extra                 | 0.5                           \n",
      " mta_tax               | 0.5                           \n",
      " tip_amount            | 0.0                           \n",
      " tolls_amount          | 0.0                           \n",
      " improvement_surcharge | 0.0                           \n",
      " total_amount          | 7.3                           \n",
      " congestion_surcharge  | 0                             \n",
      " airport_fee           | 0                             \n",
      " pickup_datetime       | NULL                          \n",
      " dropoff_datetime      | NULL                          \n",
      " service_type          | yellow                        \n",
      " run_id                | localtest                     \n",
      " source_year           | 2015                          \n",
      " source_month          | 1                             \n",
      " ingested_at_utc       | 2025-11-03 18:37:17.963346+00 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Leer muestra de Yellow Taxi\n",
    "print(\"\\nMUESTRA: raw.yellow_taxi_trip (primeras 5 filas)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "jdbc_url = get_postgres_jdbc_url()\n",
    "properties = get_postgres_properties()\n",
    "\n",
    "try:\n",
    "    yellow_sample = spark.read.jdbc(\n",
    "        url=jdbc_url,\n",
    "        table=f\"(SELECT * FROM {PG_SCHEMA_RAW}.yellow_taxi_trip LIMIT 5) as sample\",\n",
    "        properties=properties\n",
    "    )\n",
    "    yellow_sample.show(5, truncate=False, vertical=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error leyendo muestra de yellow_taxi_trip: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "473d95bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MUESTRA: raw.green_taxi_trip (primeras 5 filas)\n",
      "================================================================================\n",
      "-RECORD 0-------------------------------------------\n",
      " VendorID              | 1                          \n",
      " lpep_pickup_datetime  | 2024-10-11 10:36:29        \n",
      " lpep_dropoff_datetime | 2024-10-11 10:47:38        \n",
      " store_and_fwd_flag    | N                          \n",
      " RatecodeID            | 1                          \n",
      " PULocationID          | 97                         \n",
      " DOLocationID          | 181                        \n",
      " passenger_count       | 1                          \n",
      " trip_distance         | 2.3                        \n",
      " fare_amount           | 13.5                       \n",
      " extra                 | 0.0                        \n",
      " mta_tax               | 1.5                        \n",
      " tip_amount            | 3.75                       \n",
      " tolls_amount          | 0.0                        \n",
      " ehail_fee             | NULL                       \n",
      " improvement_surcharge | 1.0                        \n",
      " total_amount          | 18.75                      \n",
      " payment_type          | 1                          \n",
      " trip_type             | 1                          \n",
      " congestion_surcharge  | 0.0                        \n",
      " run_id                | localtest                  \n",
      " source_year           | 2024                       \n",
      " source_month          | 10                         \n",
      " ingested_at_utc       | 2025-11-03 18:30:29.771762 \n",
      " service_type          | green                      \n",
      "-RECORD 1-------------------------------------------\n",
      " VendorID              | 2                          \n",
      " lpep_pickup_datetime  | 2024-10-11 10:45:43        \n",
      " lpep_dropoff_datetime | 2024-10-11 10:53:56        \n",
      " store_and_fwd_flag    | N                          \n",
      " RatecodeID            | 1                          \n",
      " PULocationID          | 75                         \n",
      " DOLocationID          | 74                         \n",
      " passenger_count       | 5                          \n",
      " trip_distance         | 1.6                        \n",
      " fare_amount           | 10.7                       \n",
      " extra                 | 0.0                        \n",
      " mta_tax               | 0.5                        \n",
      " tip_amount            | 0.0                        \n",
      " tolls_amount          | 0.0                        \n",
      " ehail_fee             | NULL                       \n",
      " improvement_surcharge | 1.0                        \n",
      " total_amount          | 12.2                       \n",
      " payment_type          | 2                          \n",
      " trip_type             | 1                          \n",
      " congestion_surcharge  | 0.0                        \n",
      " run_id                | localtest                  \n",
      " source_year           | 2024                       \n",
      " source_month          | 10                         \n",
      " ingested_at_utc       | 2025-11-03 18:30:29.771762 \n",
      " service_type          | green                      \n",
      "-RECORD 2-------------------------------------------\n",
      " VendorID              | 2                          \n",
      " lpep_pickup_datetime  | 2024-10-11 10:26:54        \n",
      " lpep_dropoff_datetime | 2024-10-11 10:31:11        \n",
      " store_and_fwd_flag    | N                          \n",
      " RatecodeID            | 1                          \n",
      " PULocationID          | 75                         \n",
      " DOLocationID          | 41                         \n",
      " passenger_count       | 1                          \n",
      " trip_distance         | 0.99                       \n",
      " fare_amount           | 6.5                        \n",
      " extra                 | 0.0                        \n",
      " mta_tax               | 0.5                        \n",
      " tip_amount            | 1.0                        \n",
      " tolls_amount          | 0.0                        \n",
      " ehail_fee             | NULL                       \n",
      " improvement_surcharge | 1.0                        \n",
      " total_amount          | 9.0                        \n",
      " payment_type          | 1                          \n",
      " trip_type             | 1                          \n",
      " congestion_surcharge  | 0.0                        \n",
      " run_id                | localtest                  \n",
      " source_year           | 2024                       \n",
      " source_month          | 10                         \n",
      " ingested_at_utc       | 2025-11-03 18:30:29.771762 \n",
      " service_type          | green                      \n",
      "-RECORD 3-------------------------------------------\n",
      " VendorID              | 2                          \n",
      " lpep_pickup_datetime  | 2024-10-11 09:57:37        \n",
      " lpep_dropoff_datetime | 2024-10-11 10:02:38        \n",
      " store_and_fwd_flag    | N                          \n",
      " RatecodeID            | 1                          \n",
      " PULocationID          | 75                         \n",
      " DOLocationID          | 74                         \n",
      " passenger_count       | 1                          \n",
      " trip_distance         | 1.49                       \n",
      " fare_amount           | 8.6                        \n",
      " extra                 | 0.0                        \n",
      " mta_tax               | 0.5                        \n",
      " tip_amount            | 2.0                        \n",
      " tolls_amount          | 0.0                        \n",
      " ehail_fee             | NULL                       \n",
      " improvement_surcharge | 0.3                        \n",
      " total_amount          | 11.4                       \n",
      " payment_type          | 1                          \n",
      " trip_type             | 1                          \n",
      " congestion_surcharge  | 0.0                        \n",
      " run_id                | localtest                  \n",
      " source_year           | 2024                       \n",
      " source_month          | 10                         \n",
      " ingested_at_utc       | 2025-11-03 18:30:29.771762 \n",
      " service_type          | green                      \n",
      "-RECORD 4-------------------------------------------\n",
      " VendorID              | 2                          \n",
      " lpep_pickup_datetime  | 2024-10-11 10:04:29        \n",
      " lpep_dropoff_datetime | 2024-10-11 10:13:14        \n",
      " store_and_fwd_flag    | N                          \n",
      " RatecodeID            | 1                          \n",
      " PULocationID          | 74                         \n",
      " DOLocationID          | 75                         \n",
      " passenger_count       | 1                          \n",
      " trip_distance         | 1.79                       \n",
      " fare_amount           | 10.7                       \n",
      " extra                 | 0.0                        \n",
      " mta_tax               | 0.5                        \n",
      " tip_amount            | 0.0                        \n",
      " tolls_amount          | 0.0                        \n",
      " ehail_fee             | NULL                       \n",
      " improvement_surcharge | 0.3                        \n",
      " total_amount          | 11.5                       \n",
      " payment_type          | 2                          \n",
      " trip_type             | 1                          \n",
      " congestion_surcharge  | 0.0                        \n",
      " run_id                | localtest                  \n",
      " source_year           | 2024                       \n",
      " source_month          | 10                         \n",
      " ingested_at_utc       | 2025-11-03 18:30:29.771762 \n",
      " service_type          | green                      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Leer muestra de Green Taxi\n",
    "print(\"\\nMUESTRA: raw.green_taxi_trip (primeras 5 filas)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    green_sample = spark.read.jdbc(\n",
    "        url=jdbc_url,\n",
    "        table=f\"(SELECT * FROM {PG_SCHEMA_RAW}.green_taxi_trip LIMIT 5) as sample\",\n",
    "        properties=properties\n",
    "    )\n",
    "    green_sample.show(5, truncate=False, vertical=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error leyendo muestra de green_taxi_trip: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a2eb46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DISTRIBUCIÓN POR AÑO Y SERVICIO:\n",
      "================================================================================\n",
      "+----+-------+---------+\n",
      "|year|service|trips    |\n",
      "+----+-------+---------+\n",
      "|2015|green  |23194726 |\n",
      "|2015|yellow |128803794|\n",
      "|2016|green  |15933312 |\n",
      "|2016|yellow |127838281|\n",
      "|2017|green  |11445721 |\n",
      "|2017|yellow |110474320|\n",
      "|2018|green  |8588553  |\n",
      "|2018|yellow |99937427 |\n",
      "|2019|green  |5412312  |\n",
      "|2019|yellow |82020060 |\n",
      "|2020|green  |1122600  |\n",
      "|2020|yellow |23138248 |\n",
      "|2021|green  |606589   |\n",
      "|2021|yellow |28488148 |\n",
      "|2022|green  |686860   |\n",
      "|2022|yellow |36817964 |\n",
      "|2023|green  |681369   |\n",
      "|2023|yellow |35531127 |\n",
      "|2024|green  |590043   |\n",
      "|2024|yellow |35527190 |\n",
      "+----+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribución por año y servicio\n",
    "print(\"\\nDISTRIBUCIÓN POR AÑO Y SERVICIO:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    query_yellow = f\"\"\"\n",
    "    (SELECT \n",
    "        source_year as year,\n",
    "        'yellow' as service,\n",
    "        COUNT(*) as trips\n",
    "     FROM {PG_SCHEMA_RAW}.yellow_taxi_trip\n",
    "     GROUP BY source_year\n",
    "     ORDER BY source_year) as stats\n",
    "    \"\"\"\n",
    "\n",
    "    query_green = f\"\"\"\n",
    "    (SELECT \n",
    "        source_year as year,\n",
    "        'green' as service,\n",
    "        COUNT(*) as trips\n",
    "     FROM {PG_SCHEMA_RAW}.green_taxi_trip\n",
    "     GROUP BY source_year\n",
    "     ORDER BY source_year) as stats\n",
    "    \"\"\"\n",
    "\n",
    "    stats_yellow = spark.read.jdbc(url=jdbc_url, table=query_yellow, properties=properties)\n",
    "    stats_green = spark.read.jdbc(url=jdbc_url, table=query_green, properties=properties)\n",
    "\n",
    "    stats_all = stats_yellow.union(stats_green).orderBy('year', 'service')\n",
    "    stats_all.show(30, truncate=False)\n",
    "except Exception as e:\n",
    "    print(f\"Error calculando distribución: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a73d4bf",
   "metadata": {},
   "source": [
    "## 14. Verificación de calidad de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "480bc65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CALIDAD DE DATOS: raw.yellow_taxi_trip\n",
      "================================================================================\n",
      "-RECORD 0-----------------------------\n",
      " min_pickup     | 2015-01-01 00:00:00 \n",
      " max_pickup     | 2025-03-23 20:42:06 \n",
      " min_passengers | 1                   \n",
      " max_passengers | 9                   \n",
      " min_distance   | 0.01                \n",
      " max_distance   | 482.1               \n",
      " min_total      | 0.01                \n",
      " max_total      | 999.8               \n",
      " avg_total      | 18.007333323369625  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar rangos de valores en Yellow Taxi\n",
    "print(\"\\nCALIDAD DE DATOS: raw.yellow_taxi_trip\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    quality_query_yellow = f\"\"\"\n",
    "    (SELECT\n",
    "        MIN(tpep_pickup_datetime) as min_pickup,\n",
    "        MAX(tpep_pickup_datetime) as max_pickup,\n",
    "        MIN(passenger_count) as min_passengers,\n",
    "        MAX(passenger_count) as max_passengers,\n",
    "        MIN(trip_distance) as min_distance,\n",
    "        MAX(trip_distance) as max_distance,\n",
    "        MIN(total_amount) as min_total,\n",
    "        MAX(total_amount) as max_total,\n",
    "        AVG(total_amount) as avg_total\n",
    "     FROM {PG_SCHEMA_RAW}.yellow_taxi_trip) as quality\n",
    "    \"\"\"\n",
    "\n",
    "    quality_yellow = spark.read.jdbc(url=jdbc_url, table=quality_query_yellow, properties=properties)\n",
    "    quality_yellow.show(truncate=False, vertical=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error en calidad de datos (yellow): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc509992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CALIDAD DE DATOS: raw.green_taxi_trip\n",
      "================================================================================\n",
      "-RECORD 0-----------------------------\n",
      " min_pickup     | 2015-01-01 00:00:02 \n",
      " max_pickup     | 2025-01-01 22:21:15 \n",
      " min_passengers | 1                   \n",
      " max_passengers | 9                   \n",
      " min_distance   | 0.01                \n",
      " max_distance   | 450.21              \n",
      " min_total      | 0.01                \n",
      " max_total      | 999.99              \n",
      " avg_total      | 15.028900739400548  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar rangos de valores en Green Taxi\n",
    "print(\"\\nCALIDAD DE DATOS: raw.green_taxi_trip\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    quality_query_green = f\"\"\"\n",
    "    (SELECT\n",
    "        MIN(lpep_pickup_datetime) as min_pickup,\n",
    "        MAX(lpep_pickup_datetime) as max_pickup,\n",
    "        MIN(passenger_count) as min_passengers,\n",
    "        MAX(passenger_count) as max_passengers,\n",
    "        MIN(trip_distance) as min_distance,\n",
    "        MAX(trip_distance) as max_distance,\n",
    "        MIN(total_amount) as min_total,\n",
    "        MAX(total_amount) as max_total,\n",
    "        AVG(total_amount) as avg_total\n",
    "     FROM {PG_SCHEMA_RAW}.green_taxi_trip) as quality\n",
    "    \"\"\"\n",
    "\n",
    "    quality_green = spark.read.jdbc(url=jdbc_url, table=quality_query_green, properties=properties)\n",
    "    quality_green.show(truncate=False, vertical=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error en calidad de datos (green): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e0b9c",
   "metadata": {},
   "source": [
    "## 15. Exportar log de ingesta a CSV (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bacbed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Log de ingesta guardado en: ingestion_log_localtest.csv\n"
     ]
    }
   ],
   "source": [
    "# Guardar log de ingesta como CSV para documentación\n",
    "log_filename = f\"ingestion_log_{RUN_ID}.csv\"\n",
    "try:\n",
    "    log_df.to_csv(log_filename, index=False)\n",
    "    print(f\"\\n✓ Log de ingesta guardado en: {log_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"No se pudo guardar el log: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c690f8",
   "metadata": {},
   "source": [
    "## 16. Resumen final y próximos pasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "975563d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "INGESTA COMPLETADA\n",
      "================================================================================\n",
      "\n",
      "✓ Esquema RAW poblado: raw\n",
      "  - Verifica conteos y calidad en las celdas anteriores.\n",
      "✓ RUN_ID: localtest\n",
      "\n",
      "================================================================================\n",
      "PRÓXIMOS PASOS:\n",
      "================================================================================\n",
      "1. Ejecutar obt-builder para crear analytics.obt_trips\n",
      "   Comando: docker compose run obt-builder --mode full-rebuild\n",
      "\n",
      "2. Abrir notebook ML: ml_total_amount_regression.ipynb\n",
      "   - Entrenar modelos from-scratch (SGD, Ridge, Lasso, Elastic Net)\n",
      "   - Comparar con scikit-learn\n",
      "   - Evaluar y seleccionar mejor modelo\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INGESTA COMPLETADA\")\n",
    "print(\"=\"*80)\n",
    "try:\n",
    "    print(f\"\\n✓ Esquema RAW poblado: {PG_SCHEMA_RAW}\")\n",
    "    print(\"  - Verifica conteos y calidad en las celdas anteriores.\")\n",
    "except Exception as e:\n",
    "    print(f\"Resumen parcial: {e}\")\n",
    "\n",
    "print(f\"✓ RUN_ID: {RUN_ID}\")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PRÓXIMOS PASOS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. Ejecutar obt-builder para crear analytics.obt_trips\")\n",
    "print(\"   Comando: docker compose run obt-builder --mode full-rebuild\")\n",
    "print(\"\\n2. Abrir notebook ML: ml_total_amount_regression.ipynb\")\n",
    "print(\"   - Entrenar modelos from-scratch (SGD, Ridge, Lasso, Elastic Net)\")\n",
    "print(\"   - Comparar con scikit-learn\")\n",
    "print(\"   - Evaluar y seleccionar mejor modelo\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e46523",
   "metadata": {},
   "source": [
    "## Notas de implementación\n",
    "\n",
    "### Limpieza de datos aplicada:\n",
    "1. **Timestamps**: Pickup < Dropoff, rango 2015-2025, duración 1min-24hrs  \n",
    "2. **LocationID**: Válidos entre 1-263 (zonas NYC oficiales)  \n",
    "3. **Passenger count**: 1-9 pasajeros (imputa nulos a 1)  \n",
    "4. **Trip distance**: Positiva y < 500 millas  \n",
    "5. **Montos**: No negativos, total_amount < $1,000  \n",
    "6. **Códigos**: Rate code 1-6, Payment type 1-6, Vendor 1/2/4  \n",
    "7. **Consistencia**: Diferencia entre total_amount y suma de componentes ≤ $5\n",
    "\n",
    "### Metadatos agregados:\n",
    "- `run_id`: Identificador único de esta ejecución  \n",
    "- `source_year`: Año del archivo fuente  \n",
    "- `source_month`: Mes del archivo fuente  \n",
    "- `ingested_at_utc`: Timestamp UTC de la ingesta\n",
    "\n",
    "### Variables de ambiente requeridas:\n",
    "```\n",
    "PG_HOST=postgres\n",
    "PG_PORT=5432\n",
    "PG_DB=nyc_tlc\n",
    "PG_USER=postgres\n",
    "PG_PASSWORD=<tu_password>\n",
    "PG_SCHEMA_RAW=raw\n",
    "RUN_ID=ingesta_20250103_120000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90f2c7-35a6-45d1-87be-105775988a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7434b0e2-c8cf-4228-803e-d6e1242b732c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be855e5-51b8-4ab7-83af-83b7ab30fd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e3bdf1-cf00-4810-b912-a8656943f660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --mode {full,by-partition}\n",
      "                             [--year-start YEAR_START] [--year-end YEAR_END]\n",
      "                             [--months MONTHS] [--services SERVICES]\n",
      "                             [--run-id RUN_ID] [--overwrite]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --mode\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84adf17-40f0-414a-85ff-fcbc29d10d36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
